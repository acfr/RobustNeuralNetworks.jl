var documenterSearchIndex = {"docs":
[{"location":"introduction/developing/#Contributing-to-the-Package","page":"Contributing to the Package","title":"Contributing to the Package","text":"","category":"section"},{"location":"introduction/developing/","page":"Contributing to the Package","title":"Contributing to the Package","text":"All contributors welcome! Please contact nicholas.barbara@sydney.edu.au with any questions.","category":"page"},{"location":"introduction/developing/#Installation-for-Development","page":"Contributing to the Package","title":"Installation for Development","text":"","category":"section"},{"location":"introduction/developing/","page":"Contributing to the Package","title":"Contributing to the Package","text":"If you would like to contribute the package, clone the repository into your ~/.julia/dev/ directory with","category":"page"},{"location":"introduction/developing/","page":"Contributing to the Package","title":"Contributing to the Package","text":"git clone git@github.com:acfr/RobustNeuralNetworks.jl.git RobustNeuralNetworks","category":"page"},{"location":"introduction/developing/","page":"Contributing to the Package","title":"Contributing to the Package","text":"Note that the repo is RobustNeuralNetworks.jl but the folder name is RobustNeuralNetworks. This is convention for Julia packages. Navigate to the repository directory, start a Julia session, and type the following in the REPL to activate the package.","category":"page"},{"location":"introduction/developing/","page":"Contributing to the Package","title":"Contributing to the Package","text":"using Pkg\nPkg.instantiate()\nPkg.activate(\".\")","category":"page"},{"location":"introduction/developing/","page":"Contributing to the Package","title":"Contributing to the Package","text":"Check that the example in Getting Started runs without errors and matches the given output before continuing.","category":"page"},{"location":"introduction/developing/#Package-Structure","page":"Contributing to the Package","title":"Package Structure","text":"","category":"section"},{"location":"introduction/developing/","page":"Contributing to the Package","title":"Contributing to the Package","text":"The main file is src/RobustNeuralNetworks.jl. This imports all relevant packages, defines abstract types, includes code from other files, and exports the necessary components of our package. ","category":"page"},{"location":"introduction/developing/","page":"Contributing to the Package","title":"Contributing to the Package","text":"All using PackageName statements should be included in this file.\nOnly import the packages you really need\nIf you only need one function from a package, import it explicitly (not the whole package)","category":"page"},{"location":"introduction/developing/","page":"Contributing to the Package","title":"Contributing to the Package","text":"When including files in our src/ folder, the order often matters. Code should only ever be included with a single include statement in the main file. Please follow the convention outlined in the comments.","category":"page"},{"location":"introduction/developing/","page":"Contributing to the Package","title":"Contributing to the Package","text":"The source files for our package are all in the src/ directory, and are split into the following sub-directories.","category":"page"},{"location":"introduction/developing/","page":"Contributing to the Package","title":"Contributing to the Package","text":"src/Base/: Contains code relevant to the core package functionality.\nsrc/ParameterTypes/: Contains the various REN parameterisations, all of type AbstractRENParams.\nsrc/LBDN/: Contains code exclusively used for AbstractLBDN models","category":"page"},{"location":"introduction/developing/","page":"Contributing to the Package","title":"Contributing to the Package","text":"Once you have written any code for this package, be sure to test it thoroughly. Write testing scripts in the test/ directory.","category":"page"},{"location":"introduction/developing/","page":"Contributing to the Package","title":"Contributing to the Package","text":"See Test.jl documentation for help with writing good package tests.\nRun all tests for the package with ] test in the REPL.\nAll tests will be run by the CI client when submitting pull requests to the main git branch.","category":"page"},{"location":"introduction/developing/","page":"Contributing to the Package","title":"Contributing to the Package","text":"If you would like to contribute the docs, this page provides a great outline of the required workflow.","category":"page"},{"location":"introduction/developing/#Git-Workflow","page":"Contributing to the Package","title":"Git Workflow","text":"","category":"section"},{"location":"introduction/developing/","page":"Contributing to the Package","title":"Contributing to the Package","text":"The package can be treated as an independent git repository for devlopment.","category":"page"},{"location":"introduction/developing/","page":"Contributing to the Package","title":"Contributing to the Package","text":"Please feel free to submit git issues, pull requests, etc. as usual.\nAlways develop new features in a new branch labelled feature/<some_descriptive_words>. For example, the branch feature/documentation is where this documentation was first written and tested.\nSubmit pull requests once you have completed a new feature and tested it thorougly. Pull requests without thorough testing will be rejected.","category":"page"},{"location":"examples/lbdn_mnist/#Image-Classification-with-LBDN","page":"Image Classification","title":"Image Classification with LBDN","text":"","category":"section"},{"location":"examples/lbdn_mnist/","page":"Image Classification","title":"Image Classification","text":"Our next example features an LBDN trained to classify the MNIST dataset. We showed in Wang & Manchester (2023) that tuning the built-in Lipschitz bounds of LBDNs is an efficient way of designing neural networks that are robust to adversarial attacks. In this example, we will demonstrate how to train an LBDN model on the MNIST dataset with the following steps:","category":"page"},{"location":"examples/lbdn_mnist/","page":"Image Classification","title":"Image Classification","text":"Load the training and test data\nDefine a Lipschitz-bounded model\nDefine a loss function\nTrain the model to minimise the loss function\nEvaluate the trained model","category":"page"},{"location":"examples/lbdn_mnist/#.-Load-the-data","page":"Image Classification","title":"1. Load the data","text":"","category":"section"},{"location":"examples/lbdn_mnist/","page":"Image Classification","title":"Image Classification","text":"Let's start by loading the training and test data. MLDatasets.jl contains a number of common machine-learning datasets, including the MNIST dataset. To load the full dataset of 60,000 training images and 10,000 test images, one would run the following code.","category":"page"},{"location":"examples/lbdn_mnist/","page":"Image Classification","title":"Image Classification","text":"using MLDatasets: MNIST\n\n# Get MNIST training and test data\nT = Float64\nx_train, y_train = MNIST(T, split=:train)[:]\nx_test,  y_test  = MNIST(T, split=:test)[:]","category":"page"},{"location":"examples/lbdn_mnist/","page":"Image Classification","title":"Image Classification","text":"For the purposes of this example, we'll only load a small subset of the dataset.","category":"page"},{"location":"examples/lbdn_mnist/","page":"Image Classification","title":"Image Classification","text":"using BSON\n\ndata = BSON.load(\"../../src/assets/lbdn-mnist/mnist_data.bson\")\nx_train, y_train = data[\"x_train\"], data[\"y_train\"]\nx_test,  y_test  = data[\"x_test\"],  data[\"y_test\"]\n\nprintln(\"Train/test features: \", size(x_train), \" / \", size(x_test))\nprintln(\"Train/test labels:   \", size(y_train), \" / \", size(y_test))","category":"page"},{"location":"examples/lbdn_mnist/","page":"Image Classification","title":"Image Classification","text":"The feature matrices x_train and x_test are three-dimensional arrays where each 28x28 layer contains pixel data for a single handwritten number from 0 to 9. The labels y_train and y_test are vectors containing the classification of each image as a number from 0 to 9. We can convert each of these to an input/output format better suited to training with Flux.jl.","category":"page"},{"location":"examples/lbdn_mnist/","page":"Image Classification","title":"Image Classification","text":"using Flux\nusing Flux: OneHotMatrix\n\n# Reshape features for model input\nx_train = Flux.flatten(x_train)\nx_test  = Flux.flatten(x_test)\n\n# Encode categorical variables on output\ny_train = Flux.onehotbatch(y_train, 0:9)\ny_test  = Flux.onehotbatch(y_test,  0:9)\n\nprintln(\"Features: \", size(x_test))\nprintln(\"Labels:   \", size(y_test))","category":"page"},{"location":"examples/lbdn_mnist/","page":"Image Classification","title":"Image Classification","text":"Features are now stored in a Matrix where each column contains pixel data from a single image, and the labels have been converted to a OneHotMatrix where each column contains a 1 in the row corresponding to the image's classification (eg: row 2 for an image showing the number 3).","category":"page"},{"location":"examples/lbdn_mnist/#.-Define-a-model","page":"Image Classification","title":"2. Define a model","text":"","category":"section"},{"location":"examples/lbdn_mnist/","page":"Image Classification","title":"Image Classification","text":"We can now construct an LBDN model to train on the MNIST dataset. In our paper we use LBDN models with three hidden layers of (256, 356, 128) neurons (respectively) to achieve a classification accuracy of approximately 99% on the full MNIST dataset. For this example, we'll consider a smaller network and set a Lipschitz bound of γ = 5.0 to demonstrate the method.","category":"page"},{"location":"examples/lbdn_mnist/","page":"Image Classification","title":"Image Classification","text":"using Random\nusing RobustNeuralNetworks\n\n# Random seed for consistency\nrng = MersenneTwister(42)\n\n# Model specification\nnu = 28*28              # Number of inputs (size of image)\nny = 10                 # Number of outputs (possible classifications)\nnh = fill(64,2)         # 2 hidden layers, each with 64 neurons\nγ  = 5                  # Lipschitz bound of 5.0\n\n# Set up model: define parameters, then create model\nmodel_ps = DenseLBDNParams{Float64}(nu, nh, ny, γ; rng=rng)\nmodel = Chain(DiffLBDN(model_ps), Flux.softmax)\n\nprintln(typeof(model))","category":"page"},{"location":"examples/lbdn_mnist/","page":"Image Classification","title":"Image Classification","text":"The model contains a callable DiffLBDN model constructed from its direct parameterisation, which is defined by an instance of DenseLBDNParams (see the Package Overview for more detail). The output is converted to a probability distribution using a softmax layer. Note that all AbstractLBDN models can be combined with traditional neural network layers using Flux.Chain.","category":"page"},{"location":"examples/lbdn_mnist/#.-Define-a-loss-function","page":"Image Classification","title":"3. Define a loss function","text":"","category":"section"},{"location":"examples/lbdn_mnist/","page":"Image Classification","title":"Image Classification","text":"A typical loss function for training on datasets with discrete labels is the cross entropy loss. We can use the crossentropy loss function shipped with Flux.jl.","category":"page"},{"location":"examples/lbdn_mnist/","page":"Image Classification","title":"Image Classification","text":"# Loss function\nloss(model,x,y) = Flux.crossentropy(model(x), y)","category":"page"},{"location":"examples/lbdn_mnist/#.-Train-the-model","page":"Image Classification","title":"4. Train the model","text":"","category":"section"},{"location":"examples/lbdn_mnist/","page":"Image Classification","title":"Image Classification","text":"Before training the model to minimise the cross entropy loss, let's set up a callback function to evaluate the model performance during training.","category":"page"},{"location":"examples/lbdn_mnist/","page":"Image Classification","title":"Image Classification","text":"using Statistics\n\n# Check test accuracy during training\ncompare(y::OneHotMatrix, ŷ) = maximum(ŷ, dims=1) .== maximum(y.*ŷ, dims=1)\naccuracy(model, x, y::OneHotMatrix) = mean(compare(y, model(x)))\n\n# Callback function to show results while training\nfunction progress(model, iter)\n    train_loss = round(loss(model, x_train, y_train), digits=4)\n    test_acc = round(accuracy(model, x_test, y_test), digits=4)\n    @show iter train_loss test_acc\n    println()\nend","category":"page"},{"location":"examples/lbdn_mnist/","page":"Image Classification","title":"Image Classification","text":"Let's train the model over 600 epochs using two learning rates: 1e-3 for the first 300, and 1e-4 for the last 300. In both cases, we'll use the Adam optimiser and the default Flux.train! method. Once the model has been trained, we can save it for later with the BSON package.","category":"page"},{"location":"examples/lbdn_mnist/","page":"Image Classification","title":"Image Classification","text":"using BSON\n\n# Define hyperparameters and zip up data\nnum_epochs = 300\nlrs = [1e-3, 1e-4]\ndata = [(x_train, y_train)]\n\n# Train with the Adam optimiser, and display progress every 50 steps\nfor k in eachindex(lrs)\n    opt_state = Flux.setup(Adam(lrs[k]), model)\n    for i in 1:num_epochs\n        Flux.train!(loss, model, data, opt_state)\n        (i % 50 == 0) && progress(model, i)\n    end\nend\n\n# Save the model for later\nbson(\"lbdn_mnist.bson\", Dict(\"model\" => model))","category":"page"},{"location":"examples/lbdn_mnist/","page":"Image Classification","title":"Image Classification","text":"Running the training loop can take a few minutes, so here's one we prepared earlier. The model was trained on the full MNIST dataset (60,000 training images, 10,000 test images).","category":"page"},{"location":"examples/lbdn_mnist/","page":"Image Classification","title":"Image Classification","text":"model = BSON.load(\"../../src/assets/lbdn-mnist/lbdn_mnist.bson\")[\"model\"]\nprintln(typeof(model))","category":"page"},{"location":"examples/lbdn_mnist/#.-Evaluate-the-trained-model","page":"Image Classification","title":"5. Evaluate the trained model","text":"","category":"section"},{"location":"examples/lbdn_mnist/","page":"Image Classification","title":"Image Classification","text":"Our final model has a test accuracy of about 99% on this small subset of the MNIST dataset. For those interested, it achieves 97.5% accuracy on the full 10,000-image test set. We could improve this further by (for example) using a larger model, training the model for longer, or fine-tuning the learning rate. ","category":"page"},{"location":"examples/lbdn_mnist/","page":"Image Classification","title":"Image Classification","text":"# Print final results\ntrain_acc = accuracy(model, x_train, y_train)*100\ntest_acc  = accuracy(model, x_test,  y_test)*100\nprintln(\"Training accuracy: $(round(train_acc,digits=2))%\")\nprintln(\"Test accuracy:     $(round(test_acc,digits=2))%\")","category":"page"},{"location":"examples/lbdn_mnist/","page":"Image Classification","title":"Image Classification","text":"Let's have a look at some examples too.","category":"page"},{"location":"examples/lbdn_mnist/","page":"Image Classification","title":"Image Classification","text":"using CairoMakie\n\n# Make a couple of example plots\nindx = rand(rng, 1:100, 3)\nf1 = Figure(resolution = (800, 300))\nfor i in eachindex(indx)\n\n    # Get data and do prediction\n    x = x_test[:,indx[i]]\n    y = y_test[:,indx[i]]\n    ŷ = model(x)\n\n    # Reshape data for plotting\n    xmat = reshape(x, 28, 28)\n    yval = (0:9)[y][1]\n    ŷval = (0:9)[ŷ .== maximum(ŷ)][1]\n\n    # Plot results\n    ax, _ = image(\n        f1[1,i], xmat, axis=(\n            yreversed = true, \n            aspect = DataAspect(), \n            title = \"True class: $(yval), Prediction: $(ŷval)\"\n        )\n    )\n\n    # Format the plot\n    ax.xticksvisible = false\n    ax.yticksvisible = false\n    ax.xticklabelsvisible = false\n    ax.yticklabelsvisible = false\n\nend\ndisplay(f1)\nsave(\"lbdn_mnist.svg\", f1)","category":"page"},{"location":"examples/lbdn_mnist/","page":"Image Classification","title":"Image Classification","text":"(Image: )","category":"page"},{"location":"examples/pde_obsv/#PDE-Observer-Design-with-REN","page":"PDE Observer","title":"PDE Observer Design with REN","text":"","category":"section"},{"location":"examples/pde_obsv/","page":"PDE Observer","title":"PDE Observer","text":"[Example coming soon. See Section VIII of Revay, Wang & Manchester (2021).]","category":"page"},{"location":"introduction/layout/#Package-Overview","page":"Package Overview","title":"Package Overview","text":"","category":"section"},{"location":"introduction/layout/","page":"Package Overview","title":"Package Overview","text":"The RobustNeuralNetwork.jl package is divided into Recurrent Equilibrium Network (REN) and Lipschitz-Bounded Deep Network (LBDN) models.","category":"page"},{"location":"introduction/layout/#REN-Overview","page":"Package Overview","title":"REN Overview","text":"","category":"section"},{"location":"introduction/layout/","page":"Package Overview","title":"Package Overview","text":"The REN models are defined by two fundamental types:","category":"page"},{"location":"introduction/layout/","page":"Package Overview","title":"Package Overview","text":"Any subtype of AbstractRENParams holds all the information required to directly parameterise a REN satisfying some user-defined behavioural constraints.\nAny subtype of AbstractREN represents the REN in its explicit form so that it can be called and evaluated.","category":"page"},{"location":"introduction/layout/","page":"Package Overview","title":"Package Overview","text":"info: Separate Objects for Parameters and Model\nWhen working with most models (eg: RNN and LSTM) the typical workflow is to create a single instance of a model. Its parameters are updated during training, but the model object is only created once. For example:using Flux\n\n# Define a model\nmodel = Flux.RNNCell(2,5)\n\n# Train the model\nfor k in 1:num_training_epochs\n    ...                     # Run some code and compute gradients\n    Flux.update!(...)       # Update model parametersWhen working with RENs, it is much more efficient to split up the model parameterisation and the model implementation into subtypes of AbstractRENParams and AbstractREN. Converting our direct parameterisation to an explicit model for evaluation can be slow, so we only do it when the model parameters are updated:using Flux\nusing RobustNeuralNetworks\n\n# Define a model parameterisation\nparams = ContractingRENParams{Float64}(2, 5, 10, 1)\n\n# Train the model\nfor k in 1:num_training_epochs\n    model = REN(params)     # Create explicit model for evaluation\n    ...                     # Run some code and compute gradients\n    Flux.update!(...)       # Update model parametersSee the section on REN Wrappers for more details.","category":"page"},{"location":"introduction/layout/#(Direct)-Parameter-Types","page":"Package Overview","title":"(Direct) Parameter Types","text":"","category":"section"},{"location":"introduction/layout/","page":"Package Overview","title":"Package Overview","text":"Subtypes of AbstractRENParams define direct parameterisations of a REN. They are not callable models. There are four REN parameter types currently in this package:","category":"page"},{"location":"introduction/layout/","page":"Package Overview","title":"Package Overview","text":"ContractingRENParams parameterises a REN with a user-defined upper bound on the contraction rate.\nLipschitzRENParams parameterises a REN with a user-defined Lipschitz constant of gamma in (0infty).\nPassiveRENParams parameterises an input/output passive REN with user-tunable passivity parameter nu ge 0.\nGeneralRENParams parameterises a REN satisfying some generalbehavioural constraints defined by an Integral Quadratic Constraint (IQC).","category":"page"},{"location":"introduction/layout/","page":"Package Overview","title":"Package Overview","text":"For more information on these four parameterisations, please see Revay et al. (2021).","category":"page"},{"location":"introduction/layout/","page":"Package Overview","title":"Package Overview","text":"Each of these parameter types has the following collection of attributes:","category":"page"},{"location":"introduction/layout/","page":"Package Overview","title":"Package Overview","text":"A static nonlinearity nl. Common choices are Flux.relu or Flux.tanh (see Flux.jl for more information).\nModel sizes nu, nx, nv, ny defining the number of inputs, states, neurons, and outputs (respectively).\nAn instance of DirectRENParams containing the direct parameters of the REN, including all trainable parameters.\nOther attributes used to define how the direct parameterisation should be converted to the implicit model. These parameters encode the user-tunable behavioural constraints. Eg: gamma for a Lipschitz-bounded REN.","category":"page"},{"location":"introduction/layout/","page":"Package Overview","title":"Package Overview","text":"The typical workflow is to create an instance of a REN parameterisation only once. This defines all dimensions and desired properties of a REN. It is then converted to an explicit model for the REN to be evaluated.","category":"page"},{"location":"introduction/layout/#Explicit-REN-Models","page":"Package Overview","title":"Explicit REN Models","text":"","category":"section"},{"location":"introduction/layout/","page":"Package Overview","title":"Package Overview","text":"An explicit REN model must be created to call and use the network for computation. The explicit parameterisation contains all information required to evaluate a REN. We encode RENs in explicit form as subtypes of the AbstractREN type. Each subtype of AbstractREN is callable and includes the following attributes:","category":"page"},{"location":"introduction/layout/","page":"Package Overview","title":"Package Overview","text":"A static nonlinearity nl and model sizes nu, nx, nv, ny (same as AbstractRENParams.\nAn instance of ExplicitRENParams containing all REN parameters in explicit form for model evaluation (see the ExplicitRENParams docs for more detail).","category":"page"},{"location":"introduction/layout/","page":"Package Overview","title":"Package Overview","text":"Each subtype of AbstractRENParams has a method direct_to_explicit associated with it that converts the DirectRENParams struct to an instance of ExplicitRENParams satisfying the specified behavioural constraints.","category":"page"},{"location":"introduction/layout/#REN-Wrappers","page":"Package Overview","title":"REN Wrappers","text":"","category":"section"},{"location":"introduction/layout/","page":"Package Overview","title":"Package Overview","text":"There are three explicit REN wrappers currently implemented in this package. Each of them constructs a REN from a direct parameterisation params::AbstractRENParams and can be used to evaluate REN models.","category":"page"},{"location":"introduction/layout/","page":"Package Overview","title":"Package Overview","text":"REN is the basic and most commonly-used wrapper. A new instance of REN must be created whenever the parameters params are changed.","category":"page"},{"location":"introduction/layout/","page":"Package Overview","title":"Package Overview","text":"tip: REN is recommended\nWe strongly recommend using REN to train your models with Flux.jl. It is the most efficient subtype of AbstractREN that is compatible with automatic differentiation.","category":"page"},{"location":"introduction/layout/","page":"Package Overview","title":"Package Overview","text":"WrapREN includes both the DirectRENParams and ExplicitRENParams as part of the REN wrapper. When any of the direct parameters are changed, the explicit model can be updated by calling update_explicit!. This can be useful when not using automatic differentiation to train the model. For example:","category":"page"},{"location":"introduction/layout/","page":"Package Overview","title":"Package Overview","text":"using RobustNeuralNetworks\n\n# Define a model parameterisation AND a model\nparams = ContractingRENParams{Float64}(2, 5, 10, 1)\nmodel  = WrapREN(params)\n\n# Train the model\nfor k in 1:num_training_epochs\n    ...                     # Run some code and compute gradients\n    ...                     # Update model parameters\n    update_explicit!(model) # Update explicit model parameters","category":"page"},{"location":"introduction/layout/","page":"Package Overview","title":"Package Overview","text":"warning: WrapREN incompatible with Flux.jl\nSince the explicit parameters are stored in an instance of WrapREN, changing them with update_explicit! directly mutates the model. This will cause errors if the model is to be trained with Flux.jl. Use REN or DiffREN to avoid this issue.","category":"page"},{"location":"introduction/layout/","page":"Package Overview","title":"Package Overview","text":"DiffREN also includes DirectRENParams, but never stores the ExplicitRENParams. Instead, the explicit parameters are computed every time the model is evaluated. This is slow, but does not require creating a new object when the parameters are updated, and is still compatible with Flux.jl. For example:","category":"page"},{"location":"introduction/layout/","page":"Package Overview","title":"Package Overview","text":"using Flux\n\n# Define a model parameterisation AND a model\nparams = ContractingRENParams{Float64}(2, 5, 10, 1)\nmodel  = DiffREN(params)\n\n# Train the model\nfor k in 1:num_training_epochs\n    ...                     # Run some code and compute gradients\n    Flux.update!(...)       # Update model parameters","category":"page"},{"location":"introduction/layout/","page":"Package Overview","title":"Package Overview","text":"See the docstring of each wrapper and the examples (eg: PDE Observer Design with REN) for more details.","category":"page"},{"location":"introduction/layout/#LBDN-Overview","page":"Package Overview","title":"LBDN Overview","text":"","category":"section"},{"location":"introduction/layout/","page":"Package Overview","title":"Package Overview","text":"[To be written once LBDN has been properly added to the package.]","category":"page"},{"location":"introduction/layout/#Walkthrough","page":"Package Overview","title":"Walkthrough","text":"","category":"section"},{"location":"introduction/layout/","page":"Package Overview","title":"Package Overview","text":"Let's step through the example from Getting Started, which constructs and evaluates a Lipschitz-bounded REN. Start by importing packages and setting a random seed.","category":"page"},{"location":"introduction/layout/","page":"Package Overview","title":"Package Overview","text":"using Random\nusing RobustNeuralNetworks","category":"page"},{"location":"introduction/layout/","page":"Package Overview","title":"Package Overview","text":"Let's set a random seed and define our batch size and some hyperparameters. For this example, we'll build a Lipschitz-bounded REN with 4 inputs, 2 outputs, 10 states, 20 neurons, and a Lipschitz bound of γ = 1.","category":"page"},{"location":"introduction/layout/","page":"Package Overview","title":"Package Overview","text":"rng = MersenneTwister(42)\nbatches = 10\n\nnu, nx, nv, ny = 4, 10, 20, 2\nγ = 1","category":"page"},{"location":"introduction/layout/","page":"Package Overview","title":"Package Overview","text":"Let's construct the REN parameters. The variable lipschitz_ren_ps contains all the parameters required to build a Lipschitz-bounded REN.","category":"page"},{"location":"introduction/layout/","page":"Package Overview","title":"Package Overview","text":"lipschitz_ren_ps = LipschitzRENParams{Float64}(nu, nx, nv, ny, γ; rng=rng)","category":"page"},{"location":"introduction/layout/","page":"Package Overview","title":"Package Overview","text":"Once the parameters are defined, we can create a REN object in its explicit form.","category":"page"},{"location":"introduction/layout/","page":"Package Overview","title":"Package Overview","text":"ren = REN(lipschitz_ren_ps)","category":"page"},{"location":"introduction/layout/","page":"Package Overview","title":"Package Overview","text":"Now we can evaluate the REN. Note that we can use the init_states function to create a batch of initial states, all zeros, of the correct dimensions.","category":"page"},{"location":"introduction/layout/","page":"Package Overview","title":"Package Overview","text":"# Some random inputs\nx0 = init_states(ren, batches; rng=rng)\nu0 = randn(rng, ren.nu, batches)\n\n# Evaluate the REN over one timestep\nx1, y1 = ren(x0, u0)","category":"page"},{"location":"introduction/layout/","page":"Package Overview","title":"Package Overview","text":"Having evaluated the REN, we can check that the outputs are the same as in the original example.","category":"page"},{"location":"introduction/layout/","page":"Package Overview","title":"Package Overview","text":"# Print results for testing\nyout = round.(y1; digits=2)\nprintln(yout[1,:])\nprintln(yout[2,:])","category":"page"},{"location":"examples/rl/#Reinforcement-Learning-with-LBDN","page":"Reinforcement Learning","title":"Reinforcement Learning with LBDN","text":"","category":"section"},{"location":"examples/rl/","page":"Reinforcement Learning","title":"Reinforcement Learning","text":"[Example coming soon. Some examples of RL with REN can be found in Barbara, Wang & Manchester (2023).]","category":"page"},{"location":"api/#Index","page":"API","title":"Index","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"","category":"page"},{"location":"lib/models/","page":"Model Wrappers","title":"Model Wrappers","text":"Pages = [\"models.md\"]","category":"page"},{"location":"lib/models/#Model-Wrappers","page":"Model Wrappers","title":"Model Wrappers","text":"","category":"section"},{"location":"lib/models/#Lipschitz-Bounded-Deep-Networks","page":"Model Wrappers","title":"Lipschitz-Bounded Deep Networks","text":"","category":"section"},{"location":"lib/models/","page":"Model Wrappers","title":"Model Wrappers","text":"AbstractLBDN\nDiffLBDN\nLBDN","category":"page"},{"location":"lib/models/#RobustNeuralNetworks.AbstractLBDN","page":"Model Wrappers","title":"RobustNeuralNetworks.AbstractLBDN","text":"abstract type AbstractLBDN{T} end\n\nExplicit parameterisation for Lipschitz-bounded deep networks.\n\n(m::AbstractLBDN)(u::AbstractVecOrMat)\n\nCall and AbstractLBDN model given inputs u.\n\nIf arguments are matrices, each column must be a vector of inputs (allows batch simulations).\n\nExamples\n\nThis example creates a dense LBDN using DenseLBDNParams and calls the model with some randomly generated inputs.\n\nusing Random\nusing RobustNeuralNetworks\n\n# Setup\nrng = MersenneTwister(42)\nbatches = 10\nγ = 20.0\n\n# Model with 4 inputs, 1 ouput, 4 hidden layers\nnu, ny = 4, 1\nnh = [5, 10, 5, 15]\n\nlbdn_ps = DenseLBDNParams{Float64}(nu, nh, ny, γ; rng=rng)\nlbdn = LBDN(lbdn_ps)\n\n# Evaluate model with a batch of random inputs\nu = 10*randn(rng, nu, batches)\ny = lbdn(u)\n\nprintln(round.(y; digits=2))\n\n# output\n\n[-0.69 -1.89 -9.68 3.47 -11.65 -4.48 -4.53 3.61 1.37 -0.68]\n\n\n\n\n\n","category":"type"},{"location":"lib/models/#RobustNeuralNetworks.DiffLBDN","page":"Model Wrappers","title":"RobustNeuralNetworks.DiffLBDN","text":"DiffLBDN(ps::AbstractLBDNParams{T}) where T\n\nConstruct a differentiable LBDN from its direct parameterisation.\n\nDiffLBDN is an alternative to LBDN that computes the explicit parameterisation ExplicitLBDNParams each time the model is called, rather than storing it in the LBDN object.\n\nThis is slow and computationally inefficient if the model is called many times before updating the parameters (eg: in reinforcement learning). However, it can be trained just like any other Flux.jl model and does not need to be re-created if the trainable parameters are updated (unlike LBDN).\n\nSee also AbstractLBDN, LBDN.\n\n\n\n\n\n","category":"type"},{"location":"lib/models/#RobustNeuralNetworks.LBDN","page":"Model Wrappers","title":"RobustNeuralNetworks.LBDN","text":"LBDN(ps::AbstractLBDNParams{T}) where T\n\nConstruct an LBDN from its direct parameterisation.\n\nThis constructor takes a direct parameterisation of LBDN (eg: a DenseLBDNParams instance) and converts it to a callable explicit parameterisation of the LBDN.\n\nSee also AbstractLBDN, DiffLBDN.\n\n\n\n\n\n","category":"type"},{"location":"lib/models/#Recurrent-Equilibrium-Networks","page":"Model Wrappers","title":"Recurrent Equilibrium Networks","text":"","category":"section"},{"location":"lib/models/","page":"Model Wrappers","title":"Model Wrappers","text":"AbstractREN\nDiffREN\nREN\nWrapREN","category":"page"},{"location":"lib/models/#RobustNeuralNetworks.AbstractREN","page":"Model Wrappers","title":"RobustNeuralNetworks.AbstractREN","text":"abstract type AbstractREN end\n\nExplicit parameterisation for recurrent equilibrium networks.\n\n(m::AbstractREN)(xt::AbstractVecOrMat, ut::AbstractVecOrMat)\n\nCall an  AbstractREN model given internal states xt and inputs ut. \n\nIf arguments are matrices, each column must be a vector of states or inputs (allows batch simulations).\n\nExamples\n\nThis example creates a contracting REN using ContractingRENParams and calls the model with some randomly generated inputs. \n\nusing Random\nusing RobustNeuralNetworks\n\n# Setup\nrng = MersenneTwister(42)\nbatches = 10\nnu, nx, nv, ny = 4, 2, 20, 1\n\n# Construct a REN\ncontracting_ren_ps = ContractingRENParams{Float64}(nu, nx, nv, ny; rng=rng)\nren = REN(contracting_ren_ps)\n\n# Some random inputs\nx0 = init_states(ren, batches; rng=rng)\nu0 = randn(rng, ren.nu, batches)\n\n# Evaluate the REN over one timestep\nx1, y1 = ren(x0, u0)\n\nprintln(round.(y1;digits=2))\n\n# output\n\n[-1.1 0.32 0.27 0.14 -1.23 -0.4 -0.7 0.01 0.19 0.81]\n\nSee also REN, WrapREN, and DiffREN.\n\n\n\n\n\n","category":"type"},{"location":"lib/models/#RobustNeuralNetworks.DiffREN","page":"Model Wrappers","title":"RobustNeuralNetworks.DiffREN","text":"DiffREN(ps::AbstractRENParams{T}) where T\n\nConstruct a differentiable REN from its direct parameterisation.\n\nDiffREN is an alternative to REN and WrapREN that computes the explicit parameterisation ExplicitRENParams](@ref) every time the model is called, rather than storing it in the REN object.\n\nThis is slow and computationally inefficient if the model is called many times before updating the parameters (eg: in reinforcement learning). However, it can be trained just like any other Flux.jl model (unlike WrapREN) and does not need to re-created if the trainable parameters are updated (unlike REN).\n\nSee also AbstractREN, REN, and WrapREN.\n\n\n\n\n\n","category":"type"},{"location":"lib/models/#RobustNeuralNetworks.REN","page":"Model Wrappers","title":"RobustNeuralNetworks.REN","text":"REN(ps::AbstractRENParams{T}) where T\n\nConstruct a REN from its direct parameterisation.\n\nThis constructor takes a direct parameterisation of REN (eg: a GeneralRENParams instance) and converts it to a callable explicit parameterisation of the REN.\n\nSee also AbstractREN, WrapREN, and DiffREN.\n\n\n\n\n\n","category":"type"},{"location":"lib/models/#RobustNeuralNetworks.WrapREN","page":"Model Wrappers","title":"RobustNeuralNetworks.WrapREN","text":"WrapREN(ps::AbstractRENParams{T}) where T\n\nConstruct REN wrapper from its direct parameterisation.\n\nWrapREN is an alternative to REN that stores the AbstractRENParams and ExplicitRENParams within the same object. This means that a new REN object does not have to be created each time the parameters are updated. Explicit REN parameters must be updated by the user if the direct parameters have changed.\n\nNote that WrapREN cannot be used with Flux.jl, since it relies on mutating the WrapREN instance.\n\nExamples\n\nIn this example, we create a REN satisfying some generic behavioural constraints and demonstrate how to update the REN wrapper if model parameters are changed.\n\nusing LinearAlgebra\nusing Random\nusing RobustNeuralNetworks\n\n# Setup\nrng = MersenneTwister(42)\nbatches = 10\nnu, nx, nv, ny = 4, 10, 20, 2\n\nQ = Matrix{Float64}(-I(ny))\nR = 0.1^2 * Matrix{Float64}(I(nu))\nS = zeros(Float64, nu, ny)\n\n# Construct a REN\nren_ps = GeneralRENParams{Float64}(nu, nx, nv, ny, Q, S, R; rng=rng)\nren = WrapREN(ren_ps)\n\n# Some dummy inputs\nx0 = init_states(ren, batches; rng=rng)\nu0 = randn(rng, ren.nu, batches)\n\n# Evaluate the REN over one timestep\nx1, y1 = ren(x0, u0) \n\n# Update the model after changing a parameter\nren.params.direct.B2 .*= rand(rng, size(ren.params.direct.B2)...)\nupdate_explicit!(ren)\n\nprintln(round(ren.explicit.B2[10];digits=4))\n\n# output\n\n0.0109\n\nSee also AbstractREN, REN, and DiffREN.\n\n\n\n\n\n","category":"type"},{"location":"examples/lbdn_curvefit/#Fitting-a-Curve-with-LBDN","page":"Fitting a Curve","title":"Fitting a Curve with LBDN","text":"","category":"section"},{"location":"examples/lbdn_curvefit/","page":"Fitting a Curve","title":"Fitting a Curve","text":"For our first example, let's fit a Lipschitz-bounded Deep Network (LBDN) to a curve in one dimension. Consider the multiple sine-wave function below as an example.","category":"page"},{"location":"examples/lbdn_curvefit/","page":"Fitting a Curve","title":"Fitting a Curve","text":"f(x) = sin(x) + frac1Nsin(Nx)","category":"page"},{"location":"examples/lbdn_curvefit/","page":"Fitting a Curve","title":"Fitting a Curve","text":"Our aim is to demonstrate how to train a model in RobustNeuralNetworks.jl, and how to set constraints to ensure the model naturally satisfies some user-defined robustness certificate. We'll follow the steps below to fit an LBDN model to our function f(x):","category":"page"},{"location":"examples/lbdn_curvefit/","page":"Fitting a Curve","title":"Fitting a Curve","text":"Generate training data\nDefine a model with a Lipshitz bound (maximum slope) of 1.0\nDefine a loss function\nTrain the model to minimise the loss function\nExamine the trained model","category":"page"},{"location":"examples/lbdn_curvefit/#.-Generate-training-data","page":"Fitting a Curve","title":"1. Generate training data","text":"","category":"section"},{"location":"examples/lbdn_curvefit/","page":"Fitting a Curve","title":"Fitting a Curve","text":"Let's generate training data for f(x) on the interval 0 2pi and choose N = 5 as an example. We zip() the data up into a sequence of tuples (x,y) to make training with Flux.jl easier in Step 4.","category":"page"},{"location":"examples/lbdn_curvefit/","page":"Fitting a Curve","title":"Fitting a Curve","text":"# Function to estimate\nN = 5\nf(x) = sin(x)+(1/N)*sin(N*x)\n\n# Training data\ndx = 0.1\nxs = 0:dx:2π\nys = f.(xs)\ndata = zip(xs,ys)","category":"page"},{"location":"examples/lbdn_curvefit/#.-Define-a-model","page":"Fitting a Curve","title":"2. Define a model","text":"","category":"section"},{"location":"examples/lbdn_curvefit/","page":"Fitting a Curve","title":"Fitting a Curve","text":"Since we are only dealing with a simple one-dimensional curve, we can afford to use a small model. Let's choose an LBDN with four hidden layers, each with 15 neurons, and a Lipschitz bound of γ = 1.0. This means that the maximum slope the model can achieve between two points will be exactly 1.0 by construction.","category":"page"},{"location":"examples/lbdn_curvefit/","page":"Fitting a Curve","title":"Fitting a Curve","text":"using Random\nusing RobustNeuralNetworks\n\n# Random seed for consistency\nrng = MersenneTwister(42)\n\n# Model specification\nnu = 1                  # Number of inputs\nny = 1                  # Number of outputs\nnh = fill(15,4)         # 4 hidden layers, each with 15 neurons\nγ = 1                   # Lipschitz bound of 1\n\n# Set up model: define parameters, then create model\nmodel_ps = DenseLBDNParams{Float64}(nu, nh, ny, γ; rng=rng)\nmodel = DiffLBDN(model_ps)","category":"page"},{"location":"examples/lbdn_curvefit/","page":"Fitting a Curve","title":"Fitting a Curve","text":"Notice that we first constructed the model parameters model_ps defining a (dense) LBDN with DenseLBDNParams and then created a callable model with the DiffLBDN wrapper. In RobustNeuralNetworks.jl, model parameterisations are separated from the \"explicit\" definition of the model used for evaluation on data. The DiffLBDN model wrapper combines the two together in a model structure more familiar to Flux.jl users for convenience. See the Package Overview for more information.","category":"page"},{"location":"examples/lbdn_curvefit/#.-Define-a-loss-function","page":"Fitting a Curve","title":"3. Define a loss function","text":"","category":"section"},{"location":"examples/lbdn_curvefit/","page":"Fitting a Curve","title":"Fitting a Curve","text":"Let's stick to a simple loss function based on the mean-squared error (MSE) for this example. All AbstractLBDN models take an AbstractArray as their input, which is why x and y are wrapped in vectors.","category":"page"},{"location":"examples/lbdn_curvefit/","page":"Fitting a Curve","title":"Fitting a Curve","text":"# Loss function\nloss(model,x,y) = Flux.mse(model([x]),[y]) ","category":"page"},{"location":"examples/lbdn_curvefit/#.-Train-the-model","page":"Fitting a Curve","title":"4. Train the model","text":"","category":"section"},{"location":"examples/lbdn_curvefit/","page":"Fitting a Curve","title":"Fitting a Curve","text":"Our objective is to minimise the MSE loss function with a model that has a Lipschitz bound no greater than 1.0. Let's set up a callback function to check the fit error and slope of our model at each training epoch.","category":"page"},{"location":"examples/lbdn_curvefit/","page":"Fitting a Curve","title":"Fitting a Curve","text":"using Flux\n\n# Check fit error/slope during training\nmse(model, xs, ys) = sum(loss.((model,), xs, ys)) / length(xs)\nlip(model, xs, dx) = maximum(abs.(diff(model(xs'), dims=2)))/dx\n\n# Callback function to show results while training\nfunction progress(model, iter, xs, ys, dx) \n    fit_error = round(mse(model, xs, ys), digits=4)\n    slope = round(lip(model, xs, dx), digits=4)\n    @show iter fit_error slope\n    println()\nend","category":"page"},{"location":"examples/lbdn_curvefit/","page":"Fitting a Curve","title":"Fitting a Curve","text":"We'll train the model for 200 training epochs a learning rate of lr = 2e-4. We'll also use the Adam optimiser from Flux.jl and the default Flux.train! method.","category":"page"},{"location":"examples/lbdn_curvefit/","page":"Fitting a Curve","title":"Fitting a Curve","text":"# Define hyperparameters and optimiser\nnum_epochs = 200\nlr = 2e-4\nopt_state = Flux.setup(Adam(lr), model)\n\n# Train the model\nfor i in 1:num_epochs\n    Flux.train!(loss, model, data, opt_state)\n    (i % 100 == 0) && progress(model, i, xs, ys, dx)\nend","category":"page"},{"location":"examples/lbdn_curvefit/","page":"Fitting a Curve","title":"Fitting a Curve","text":"Note that this training loop is for demonstration only. For a better fit, and indeed on more complex problems, we strongly recommend:","category":"page"},{"location":"examples/lbdn_curvefit/","page":"Fitting a Curve","title":"Fitting a Curve","text":"Increasing the number of training epochs\nDefining your own training loop \nUsing ParameterSchedulers.jl to vary the learning rate.","category":"page"},{"location":"examples/lbdn_curvefit/#.-Examine-the-trained-model","page":"Fitting a Curve","title":"5. Examine the trained model","text":"","category":"section"},{"location":"examples/lbdn_curvefit/","page":"Fitting a Curve","title":"Fitting a Curve","text":"We can now plot the results to see what our model looks like.","category":"page"},{"location":"examples/lbdn_curvefit/","page":"Fitting a Curve","title":"Fitting a Curve","text":"using CairoMakie\n\n# Create a figure\nf1 = Figure(resolution = (600, 400))\nax = Axis(f1[1,1], xlabel=\"x\", ylabel=\"y\")\n\nŷ = map(x -> model([x])[1], xs)\nlines!(xs, ys, label = \"Data\")\nlines!(xs, ŷ, label = \"LBDN\")\naxislegend(ax)\nsave(\"lbdn_curve_fit.svg\", f1)","category":"page"},{"location":"examples/lbdn_curvefit/","page":"Fitting a Curve","title":"Fitting a Curve","text":"(Image: )","category":"page"},{"location":"examples/lbdn_curvefit/","page":"Fitting a Curve","title":"Fitting a Curve","text":"The model roughly approximates the multiple sine-wave f(x), but maintains a maximum Lipschitz constant (slope on the graph) below 1. ","category":"page"},{"location":"examples/lbdn_curvefit/","page":"Fitting a Curve","title":"Fitting a Curve","text":"# Estimate Lipschitz lower-bound\nlip(model, xs, dx) = maximum(abs.(diff(model(xs'), dims=2)))/dx\nprintln(\"Empirical lower Lipschitz bound: \", round(lip(model, xs, dx); digits=2))","category":"page"},{"location":"examples/lbdn_curvefit/","page":"Fitting a Curve","title":"Fitting a Curve","text":"The benefit of using an LBDN is that we have full control over the Lipschitz bound, and can still use standard unconstrained gradient descent tools lile Flux.train! to train our models. For examples in which setting the Lipschitz bound improves model performance and robustness, see Image Classification with LBDN and Reinforcement Learning with LBDN.","category":"page"},{"location":"introduction/getting_started/#Getting-Started","page":"Getting Started","title":"Getting Started","text":"","category":"section"},{"location":"introduction/getting_started/#Installation","page":"Getting Started","title":"Installation","text":"","category":"section"},{"location":"introduction/getting_started/","page":"Getting Started","title":"Getting Started","text":"RobustNeuralNetworks.jl is written in Julia and can be installed with the in-built package manager. To add the package, type the following into the REPL.","category":"page"},{"location":"introduction/getting_started/","page":"Getting Started","title":"Getting Started","text":"] add RobustNeuralNetworks","category":"page"},{"location":"introduction/getting_started/#Basic-Usage","page":"Getting Started","title":"Basic Usage","text":"","category":"section"},{"location":"introduction/getting_started/","page":"Getting Started","title":"Getting Started","text":"You should now be able to construct robust neural network models. The following example constructs a Lipschitz-bounded REN and evalutates it given a batch of random initial states and inputs.","category":"page"},{"location":"introduction/getting_started/","page":"Getting Started","title":"Getting Started","text":"using Random\nusing RobustNeuralNetworks\n\n# Setup\nrng = MersenneTwister(42)\nbatches = 10\nnu, nx, nv, ny = 4, 10, 20, 1\nγ = 1\n\n# Construct a REN\nlipschitz_ren_ps = LipschitzRENParams{Float64}(nu, nx, nv, ny, γ; rng=rng)\nren = REN(lipschitz_ren_ps)\n\n# Some random inputs\nx0 = init_states(ren, batches; rng=rng)\nu0 = randn(rng, ren.nu, batches)\n\n# Evaluate the REN over one timestep\nx1, y1 = ren(x0, u0)\n\n# Print results for testing\nprintln(round.(y1; digits=2))\n\n# output\n\n[0.23 -0.01 -0.06 0.15 -0.03 -0.11 0.0 0.42 0.24 0.22]","category":"page"},{"location":"introduction/getting_started/","page":"Getting Started","title":"Getting Started","text":"See Package Overview for a detailed walkthrough of this example. For a detailed example of training models from RobustNeuralNetworks.jl, we recommend starting with Fitting a Curve with LBDN.","category":"page"},{"location":"lib/functions/","page":"Functions","title":"Functions","text":"Pages = [\"functions.md\"]","category":"page"},{"location":"lib/functions/#Functions","page":"Functions","title":"Functions","text":"","category":"section"},{"location":"lib/functions/","page":"Functions","title":"Functions","text":"direct_to_explicit\ninit_states\nset_output_zero!\nupdate_explicit!","category":"page"},{"location":"lib/functions/#RobustNeuralNetworks.direct_to_explicit","page":"Functions","title":"RobustNeuralNetworks.direct_to_explicit","text":"direct_to_explicit(ps::AbstractRENParams{T}, return_h=false) where T\n\nConvert direct parameterisation of RENs to explicit parameterisation.\n\nUses the parameterisation encoded in ps to construct an ExplicitRENParams object that naturally satisfies a set of user-defined behavioural constraints.\n\nArguments\n\nps::AbstractRENParams: Direct parameterisation with behavioural constraints to convert to an explicit parameterisation of REN (eg: GeneralRENParams).\nreturn_h::Bool=false: Whether to return the H-matrix directly (see Revay et al. (2021)). Useful for debugging or model analysis. If false, function returns an object of type ExplicitRENParams{T}. \n\nSee also GeneralRENParams, ContractingRENParams, LipschitzRENParams, PassiveRENParams.\n\n\n\n\n\ndirect_to_explicit(ps::AbstractRENParams{T}) where T\n\nConvert direct parameterisation of LBDNs to explicit parameterisation.\n\nUses the parameterisation encoded in ps to construct an ExplicitLBDNParams object that naturally respects a user-defined Lipschitz bound.\n\nArguments\n\nps::AbstractLBDNParams: Direct parameterisation of an LBDN to convert to an explicit parameterisation for model evaluation (eg: DenseLBDNParams).\n\nSee also DenseLBDNParams.\n\n\n\n\n\n","category":"function"},{"location":"lib/functions/#RobustNeuralNetworks.init_states","page":"Functions","title":"RobustNeuralNetworks.init_states","text":"init_states(m::AbstractREN, nbatches; rng=nothing)\n\nReturn matrix of (nbatches) state vectors of a REN initialised as zeros.\n\n\n\n\n\n","category":"function"},{"location":"lib/functions/#RobustNeuralNetworks.set_output_zero!","page":"Functions","title":"RobustNeuralNetworks.set_output_zero!","text":"set_output_zero!(m::AbstractREN)\n\nSet output map of a REN to zero.\n\nIf the resulting model is called with x1,y = ren(x,u) then y = 0 for any x and u.\n\n\n\n\n\nset_output_zero!(m::AbstractLBDN)\n\nSet output map of an LBDN to zero.\n\nIf the resulting model is called with y = lbdn(u) then y = 0 for any u.\n\n\n\n\n\n","category":"function"},{"location":"lib/functions/#RobustNeuralNetworks.update_explicit!","page":"Functions","title":"RobustNeuralNetworks.update_explicit!","text":"update_explicit!(m::WrapREN)\n\nUpdate explicit model in WrapREN using the current direct parameters.\n\n\n\n\n\n","category":"function"},{"location":"examples/ren_ctrl/#Nonlinear-Control-Design-with-REN","page":"Nonlinear Control","title":"Nonlinear Control Design with REN","text":"","category":"section"},{"location":"examples/ren_ctrl/","page":"Nonlinear Control","title":"Nonlinear Control","text":"[Example coming soon. See Section IX of Revay, Wang & Manchester (2021).]","category":"page"},{"location":"lib/model_params/","page":"Model Parameterisations","title":"Model Parameterisations","text":"Pages = [\"model_params.md\"]","category":"page"},{"location":"lib/model_params/#Model-Parameterisations","page":"Model Parameterisations","title":"Model Parameterisations","text":"","category":"section"},{"location":"lib/model_params/#Lipschitz-Bounded-Deep-Networks","page":"Model Parameterisations","title":"Lipschitz-Bounded Deep Networks","text":"","category":"section"},{"location":"lib/model_params/","page":"Model Parameterisations","title":"Model Parameterisations","text":"AbstractLBDNParams\nDenseLBDNParams\nDirectLBDNParams\nExplicitLBDNParams","category":"page"},{"location":"lib/model_params/#RobustNeuralNetworks.AbstractLBDNParams","page":"Model Parameterisations","title":"RobustNeuralNetworks.AbstractLBDNParams","text":"abstract type AbstractLBDNParams{T} end\n\nDirect parameterisation for Lipschitz-bounded deep networks.\n\n\n\n\n\n","category":"type"},{"location":"lib/model_params/#RobustNeuralNetworks.DenseLBDNParams","page":"Model Parameterisations","title":"RobustNeuralNetworks.DenseLBDNParams","text":"DenseLBDNParams{T}(nu, nh, ny, γ; <keyword arguments>) where T\n\nConstruct direct parameterisation of a dense (fully-connected) LBDN.\n\nThis is the equivalent of a multi-layer perceptron (eg: Flux.Dense) with a guaranteed Lipschitz bound of γ.\n\nArguments\n\nnu::Int: Number of inputs.\nnh::Vector{Int}: Number of hidden units for each layer. Eg: nh = [5,10] for 2 hidden layers with 5 and 10 nodes (respectively).\nny::Int: Number of outputs.\nγ::Number=T(1): Lipschitz upper bound.\n\nKeyword arguments:\n\nnl::Function=Flux.relu: Sector-bounded static nonlinearity.\n\nSee DirectLBDNParams for documentation of keyword arguments initW, initb, rng.\n\n\n\n\n\n","category":"type"},{"location":"lib/model_params/#RobustNeuralNetworks.DirectLBDNParams","page":"Model Parameterisations","title":"RobustNeuralNetworks.DirectLBDNParams","text":"DirectLBDNParams{T}(nu, nh, ny; <keyword arguments>) where T\n\nConstruct direct parameterisation for a Lipschitz-bounded deep network.\n\nThis is typically used by a higher-level constructor to define an LBDN model, which takes the direct parameterisation in DirectLBDNParams and defines rules for converting it to an explicit parameterisation. See for example DenseLBDNParams.\n\nArguments\n\nnu::Int: Number of inputs.\nnh::Vector{Int}: Number of hidden units for each layer. Eg: nh = [5,10] for 2 hidden layers with 5 and 10 nodes (respectively).\nny::Int: Number of outputs.\n\nKeyword arguments\n\ninitW::Function=Flux.glorot_normal: Initialisation function for implicit params X,Y,d.\ninitb::Function=Flux.glorot_normal: Initialisation function for bias vectors.\nrng::AbstractRNG = Random.GLOBAL_RNG: rng for model initialisation.\n\nSee Wang et al. (2023) for parameterisation details.\n\nSee also DenseLBDNParams.\n\n\n\n\n\n","category":"type"},{"location":"lib/model_params/#RobustNeuralNetworks.ExplicitLBDNParams","page":"Model Parameterisations","title":"RobustNeuralNetworks.ExplicitLBDNParams","text":"mutable struct ExplicitLBDNParams{T, N, M}\n\nExplicit LBDN parameter struct.\n\nThese parameters define the explicit form of a Lipschitz-bounded deep network used for model evaluation. Parameters are stored in NTuples, where each element of an NTuple is the parameter for a single layer of the network. Tuples are faster to work with than vectors of arrays.\n\nSee Wang et al. (2023) for more details on explicit parameterisations of LBDN.\n\n\n\n\n\n","category":"type"},{"location":"lib/model_params/#Recurrent-Equilibrium-Networks","page":"Model Parameterisations","title":"Recurrent Equilibrium Networks","text":"","category":"section"},{"location":"lib/model_params/","page":"Model Parameterisations","title":"Model Parameterisations","text":"AbstractRENParams\nContractingRENParams\nDirectRENParams\nExplicitRENParams\nGeneralRENParams\nLipschitzRENParams\nPassiveRENParams","category":"page"},{"location":"lib/model_params/#RobustNeuralNetworks.AbstractRENParams","page":"Model Parameterisations","title":"RobustNeuralNetworks.AbstractRENParams","text":"abstract type AbstractRENParams{T} end\n\nDirect parameterisation for recurrent equilibrium networks.\n\n\n\n\n\n","category":"type"},{"location":"lib/model_params/#RobustNeuralNetworks.ContractingRENParams","page":"Model Parameterisations","title":"RobustNeuralNetworks.ContractingRENParams","text":"ContractingRENParams{T}(nu, nx, nv, ny; <keyword arguments>) where T\n\nConstruct direct parameterisation of a contracting REN.\n\nThe parameters can be used to construct an explicit REN model that has guaranteed, built-in contraction properties.\n\nArguments\n\nnu::Int: Number of inputs.\nnx::Int: Number of states.\nnv::Int: Number of neurons.\nny::Int: Number of outputs.\n\nKeyword arguments\n\nnl::Function=Flux.relu: Sector-bounded static nonlinearity.\nαbar::T=1: Upper bound on the contraction rate with ᾱ ∈ (0,1].\n\nSee DirectRENParams for documentation of keyword arguments init, ϵ, bx_scale, bv_scale, polar_param, D22_zero, is_output, rng.\n\nSee also GeneralRENParams, LipschitzRENParams, PassiveRENParams.\n\n\n\n\n\nContractingRENParams(nv, A, B, C, D; ...)\n\nAlternative constructor for ContractingRENParams that initialises the REN from a stable discrete-time linear system with state-space model\n\nbeginalign*\nx_t+1 = Ax_t + Bu_t \ny_t = Cx_t + Du_t\nendalign*\n\n[TODO:] This method may be removed in a later edition of the package.\n\n[TODO:] Make compatible with αbar ≠ 1.0.\n\n\n\n\n\n","category":"type"},{"location":"lib/model_params/#RobustNeuralNetworks.DirectRENParams","page":"Model Parameterisations","title":"RobustNeuralNetworks.DirectRENParams","text":"DirectRENParams{T}(nu, nx, nv; <keyword arguments>) where T\n\nConstruct direct parameterisation for an (acyclic) recurrent equilibrium network.\n\nThis is typically used by higher-level constructors when defining a REN, which take the direct parameterisation and define rules for converting it to an explicit parameterisation. See for example GeneralRENParams.\n\nArguments\n\nnu::Int: Number of inputs.\nnx::Int: Number of states.\nnv::Int: Number of neurons.\n\nKeyword arguments\n\ninit=:random: Initialisation method. Options are:\n:random: Random sampling for all parameters.\n:cholesky: Compute X with cholesky factorisation of H, sets E,F,P = I.\npolar_param::Bool=true: Use polar parameterisation to construct H matrix from X in REN parameterisation (recommended).\nD22_free::Bool=false: Specify whether to train D22 as a free parameter (true), or construct it separately from X3, Y3, Z3 (false). Typically use D22_free = true only for a contracting REN.\nD22_zero::Bool=false: Fix D22 = 0 to remove any feedthrough.\nbx_scale::T=0: Set scale of initial state bias vector bx.\nbv_scale::T=1: Set scalse of initial neuron input bias vector bv.\nis_output::Bool=true: Include output layer y_t = C_2 x_t + D_21 w_t + D_22 u_t + b_y.\nϵ::T=1e-12: Regularising parameter for positive-definite matrices.\nrng::AbstractRNG=Random.GLOBAL_RNG: rng for model initialisation.\n\nSee Revay et al. (2021) for parameterisation details.\n\nSee also GeneralRENParams, ContractingRENParams, LipschitzRENParams, PassiveRENParams.\n\n\n\n\n\n","category":"type"},{"location":"lib/model_params/#RobustNeuralNetworks.ExplicitRENParams","page":"Model Parameterisations","title":"RobustNeuralNetworks.ExplicitRENParams","text":"mutable struct ExplicitRENParams{T}\n\nExplicit REN parameter struct.\n\nThese parameters define a recurrent equilibrium network with model inputs and outputs u_t y_t, neuron inputs and outputs v_tw_t, and states x_t.\n\nbeginequation*\nbeginbmatrix\nx_t+1  v_t  y_t\nendbmatrix\n= \nbeginbmatrix\nA  B_1  B_2 \nC_1  D_11  D_12 \nC_2  D_21  D_22 \nendbmatrix\nbeginbmatrix\nx_t  w_t  u_t\nendbmatrix\n+ \nbeginbmatrix\nb_x  b_v  b_y\nendbmatrix\nendequation*\n\nSee Revay et al. (2021) for more details on explicit parameterisations of REN.\n\n\n\n\n\n","category":"type"},{"location":"lib/model_params/#RobustNeuralNetworks.GeneralRENParams","page":"Model Parameterisations","title":"RobustNeuralNetworks.GeneralRENParams","text":"GeneralRENParams{T}(nu, nx, nv, ny, Q, S, R; <keyword arguments>) where T\n\nConstruct direct parameterisation of a REN satisfying general behavioural constraints.\n\nBehavioural constraints are encoded by the matrices Q,S,R in an incremental Integral Quadratic Constraint (IQC). See Equation 4 of Revay et al. (2021).\n\nArguments\n\nnu::Int: Number of inputs.\nnx::Int: Number of states.\nnv::Int: Number of neurons.\nny::Int: Number of outputs.\nQ::Matrix{T}: IQC weight matrix on model outputs\nS::Matrix{T}: IQC coupling matrix on model outputs/inputs\nR::Matrix{T}: IQC weight matrix on model outputs\n\nKeyword arguments\n\nnl::Function=Flux.relu: Sector-bounded static nonlinearity.\nαbar::T=1: Upper bound on the contraction rate with ᾱ ∈ (0,1].\n\nSee DirectRENParams for documentation of keyword arguments init, ϵ, bx_scale, bv_scale, polar_param, rng.\n\nSee also ContractingRENParams, LipschitzRENParams, PassiveRENParams.\n\n\n\n\n\n","category":"type"},{"location":"lib/model_params/#RobustNeuralNetworks.LipschitzRENParams","page":"Model Parameterisations","title":"RobustNeuralNetworks.LipschitzRENParams","text":"LipschitzRENParams(nu, nx, nv, ny, γ; <keyword arguments>) where T\n\nConstruct direct parameterisation of a REN with a Lipschitz bound of γ.\n\nArguments\n\nnu::Int: Number of inputs.\nnx::Int: Number of states.\nnv::Int: Number of neurons.\nny::Int: Number of outputs.\nγ::Number: Lipschitz upper bound.\n\nKeyword arguments\n\nnl::Function=Flux.relu: Sector-bounded static nonlinearity.\nαbar::T=1: Upper bound on the contraction rate with ᾱ ∈ (0,1].\n\nSee DirectRENParams for documentation of keyword arguments init, ϵ, bx_scale, bv_scale, polar_param, D22_zero, rng.\n\nSee also GeneralRENParams, ContractingRENParams, PassiveRENParams.\n\n\n\n\n\n","category":"type"},{"location":"lib/model_params/#RobustNeuralNetworks.PassiveRENParams","page":"Model Parameterisations","title":"RobustNeuralNetworks.PassiveRENParams","text":"PassiveRENParams{T}(nu, nx, nv, ny; <keyword arguments>) where T\n\nConstruct direct parameterisation of a passive REN.\n\nArguments\n\nnu::Int: Number of inputs.\nnx::Int: Number of states.\nnv::Int: Number of neurons.\nny::Int: Number of outputs.\n\nKeyword arguments\n\nν::T=0: Passivity parameter. Use ν>0 for incrementally strictly input passive model, and ν == 0 for incrementally passive model. \nnl::Function=Flux.relu: Sector-bounded static nonlinearity.\nαbar::T=1: Upper bound on the contraction rate with ᾱ ∈ (0,1].\n\nSee DirectRENParams for documentation of keyword arguments init, ϵ, bx_scale, bv_scale, polar_param, rng.\n\nSee also GeneralRENParams, ContractingRENParams, LipschitzRENParams.\n\n\n\n\n\n","category":"type"},{"location":"#RobustNeuralNetworks.jl-Documentation","page":"Home","title":"RobustNeuralNetworks.jl Documentation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Bringing robust machine learning to Julia.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Welcome to the documentation for RobustNeuralNetworks.jl! This package contains neural network models that are constructed to naturally satisfy robustness constraints, all in native Julia.","category":"page"},{"location":"#Why-Robust-Models?","page":"Home","title":"Why Robust Models?","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Modern machine learning relies heavily on rapidly training and evaluating neural networks in problems ranging from image classification to robotic control. Most existing neural network architectures have no robustness certificates, making them sensitive to poor data quality, adversarial attacks, and other input perturbations. The few neural network architectures proposed in recent years that offer solutions to this brittle behaviour rely on explicitly enforcing constraints during training to “smooth” the network response. These methods are computationally expensive, making them slow and difficult to scale up to complex real-world problems.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Recently, we proposed the Recurrent Equilibrium Network (REN) architecture as computationally efficient solutions to these problems. The REN architecture is flexible in that it includes all commonly used neural network models, such as fully-connected networks, convolutional neural networks, and recurrent neural networks. The weight matrices and bias vectors in a REN are directly parameterised to naturally satisfy behavioural constraints chosen by the user. For example, the user can build a REN with a given Lipschitz constant to ensure the output of the network is quantifiably less sensitive to unexpected input perturbations. ","category":"page"},{"location":"","page":"Home","title":"Home","text":"The direct parameterisation of RENs means that we can train RENs with standard, unconstrained optimization methods (such as gradient descent) while also guaranteeing their robustness. Achieving the “best of both worlds” in this way is the main advantage of our REN/LBDN model classes, and allows us to freely train them for common machine learning problems as well as more difficult applications where safety and robustness are critical.","category":"page"},{"location":"","page":"Home","title":"Home","text":"[TODO: Add comments on LBDN when properly added to the package.]","category":"page"},{"location":"#Introduction","page":"Home","title":"Introduction","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Pages = [\"introduction/getting_started.md\", \"introduction/layout.md\", \"introduction/developing.md\"]\nDepth = 1","category":"page"},{"location":"#Examples","page":"Home","title":"Examples","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Pages = [\"examples/lbdn_curvefit.md\", \"examples/lbdn_mnist.md\", \"examples/rl.md\", \"examples/pde_obsv.md\", \"examples/ren_ctrl.md\"]\nDepth = 1","category":"page"},{"location":"#Library","page":"Home","title":"Library","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Pages = [\"lib/models.md\", \"lib/model_params.md\", \"lib/functions.md\"]\nDepth = 1","category":"page"},{"location":"#Research-Papers","page":"Home","title":"Research Papers","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"RobustNeurlaNetworks.jl is built on the REN and LBDN model parameterisations described in the following two papers (respectively):","category":"page"},{"location":"","page":"Home","title":"Home","text":"M. Revay, R. Wang, and I. R. Manchester, \"Recurrent equilibrium networks: Flexible dynamic models with guaranteed stability and robustness,\" April 2021. doi: https://doi.org/10.48550/arXiv.2104.05942.","category":"page"},{"location":"","page":"Home","title":"Home","text":"R. Wang and I. R. Manchester, \"Direct parameterization of Lipschitz-bounded deep networks,\" January 2023. doi: https://doi.org/10.48550/arXiv.2301.11526.","category":"page"},{"location":"","page":"Home","title":"Home","text":"The REN parameterisation was extended to continuous-time systems in:","category":"page"},{"location":"","page":"Home","title":"Home","text":"D. Martinelli, C. L. Galimberti, I. R. Manchester, L. Furieri, and G. Ferrari-Trecate, \"Unconstrained Parametrization of Dissipative and Contracting Neural Ordinary Differential Equations,\" April 2023. doi: https://doi.org/10.48550/arXiv.2304.02976.","category":"page"},{"location":"","page":"Home","title":"Home","text":"See below for a collection of projects and papers using RobustNeuralNetworks.jl.","category":"page"},{"location":"","page":"Home","title":"Home","text":"N. H. Barbara, R. Wang, and I. R. Manchester, \"Learning Over All Contracting and Lipschitz Closed-Loops for Partially-Observed Nonlinear Systems,\" April 2023. doi: https://doi.org/10.48550/arXiv.2304.06193.","category":"page"}]
}
