<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Home · RobustNeuralNetworks.jl</title><script data-outdated-warner src="assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="assets/documenter.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="index.html">RobustNeuralNetworks.jl</a></span></div><form class="docs-search" action="search.html"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li class="is-active"><a class="tocitem" href="index.html">Home</a><ul class="internal"><li><a class="tocitem" href="#Examples"><span>Examples</span></a></li><li><a class="tocitem" href="#Index"><span>Index</span></a></li><li><a class="tocitem" href="#Docstrings"><span>Docstrings</span></a></li><li><a class="tocitem" href="#TODO:"><span>TODO:</span></a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href="index.html">Home</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href="index.html">Home</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/acfr/RobustNeuralNetworks.jl/blob/main/docs/src/index.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="RobustNeuralNetworks.jl-Documentation"><a class="docs-heading-anchor" href="#RobustNeuralNetworks.jl-Documentation">RobustNeuralNetworks.jl Documentation</a><a id="RobustNeuralNetworks.jl-Documentation-1"></a><a class="docs-heading-anchor-permalink" href="#RobustNeuralNetworks.jl-Documentation" title="Permalink"></a></h1><p><em>Bringing robust machine learning to Julia.</em></p><ul><li><a href="index.html#RobustNeuralNetworks.jl-Documentation">RobustNeuralNetworks.jl Documentation</a></li><li class="no-marker"><ul><li><a href="index.html#Examples">Examples</a></li><li><a href="index.html#Index">Index</a></li><li><a href="index.html#Docstrings">Docstrings</a></li><li><a href="index.html#TODO:">TODO:</a></li></ul></li></ul><h2 id="Examples"><a class="docs-heading-anchor" href="#Examples">Examples</a><a id="Examples-1"></a><a class="docs-heading-anchor-permalink" href="#Examples" title="Permalink"></a></h2><p>Here&#39;s an example. You should be able to see the import statement of <code>Random</code>.</p><pre><code class="language-julia hljs">using Random
a = 1
b = 2*rand()
2a + b</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">2.532605288485002</code></pre><p>Can we continue using variables from this example?</p><pre><code class="language-julia hljs">println(a+b)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">1.5326052884850019</code></pre><p>We can even make things look like the REPL.</p><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; a = 1</code><code class="nohighlight hljs ansi" style="display:block;">1</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; b = 2</code><code class="nohighlight hljs ansi" style="display:block;">2</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; a + b</code><code class="nohighlight hljs ansi" style="display:block;">3</code></pre><p>We can even delay execution of an example over a few different example blocks. Start a for loop here...</p><pre><code class="language-julia hljs">for i in 1:3
    j = i^2</code></pre><p>Then write something insightful and finish it below...</p><pre><code class="language-julia hljs">    println(j)
end</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">1
4
9</code></pre><p>It&#39;s worth having a look at the <code>@setup</code> macro as well when you can. It will make it much easier to write examples that include a number of lines of setup which should be hidden. Having said that, it might be useful to show the reader how you set up the example!</p><p>Most of your examples should be written with the <code>@jldoctest</code> macro. I&#39;ll give it a go below, but have a look at how <code>ControlSystems.jl</code> does things too.</p><p>Example:</p><pre><code class="language- hljs">using Random
using RobustNeuralNetworks

batches = 50
nu, nx, nv, ny = 4, 10, 20, 2

contracting_ren_ps = ContractingRENParams{Float64}(nu, nx, nv, ny)
contracting_ren = REN(contracting_ren_ps)

x0 = init_states(contracting_ren, batches)
u0 = randn(contracting_ren.nu, batches)

x1, y1 = contracting_ren(x0, u0)  # Evaluates the REN over one timestep

println(size(y1))

# output

(2, 50)</code></pre><h2 id="Index"><a class="docs-heading-anchor" href="#Index">Index</a><a id="Index-1"></a><a class="docs-heading-anchor-permalink" href="#Index" title="Permalink"></a></h2><ul><li><a href="index.html#RobustNeuralNetworks.AbstractLBDN"><code>RobustNeuralNetworks.AbstractLBDN</code></a></li><li><a href="index.html#RobustNeuralNetworks.AbstractREN"><code>RobustNeuralNetworks.AbstractREN</code></a></li><li><a href="index.html#RobustNeuralNetworks.AbstractREN-Tuple{VecOrMat{T} where T, VecOrMat{T} where T}"><code>RobustNeuralNetworks.AbstractREN</code></a></li><li><a href="index.html#RobustNeuralNetworks.AbstractRENParams"><code>RobustNeuralNetworks.AbstractRENParams</code></a></li><li><a href="index.html#RobustNeuralNetworks.ContractingRENParams-Union{Tuple{T}, Tuple{Int64, AbstractMatrix{T}, AbstractMatrix{T}, AbstractMatrix{T}, AbstractMatrix{T}}} where T"><code>RobustNeuralNetworks.ContractingRENParams</code></a></li><li><a href="index.html#RobustNeuralNetworks.ContractingRENParams-Union{NTuple{4, Int64}, Tuple{T}} where T"><code>RobustNeuralNetworks.ContractingRENParams</code></a></li><li><a href="index.html#RobustNeuralNetworks.DiffREN-Union{Tuple{AbstractRENParams{T}}, Tuple{T}} where T"><code>RobustNeuralNetworks.DiffREN</code></a></li><li><a href="index.html#RobustNeuralNetworks.DiffREN"><code>RobustNeuralNetworks.DiffREN</code></a></li><li><a href="index.html#RobustNeuralNetworks.DirectParams-Union{NTuple{4, Int64}, Tuple{T}} where T"><code>RobustNeuralNetworks.DirectParams</code></a></li><li><a href="index.html#RobustNeuralNetworks.ExplicitParams"><code>RobustNeuralNetworks.ExplicitParams</code></a></li><li><a href="index.html#RobustNeuralNetworks.GeneralRENParams-Union{Tuple{T}, Tuple{Int64, Int64, Int64, Int64, Matrix{T}, Matrix{T}, Matrix{T}}} where T"><code>RobustNeuralNetworks.GeneralRENParams</code></a></li><li><a href="index.html#RobustNeuralNetworks.LBFN-Union{Tuple{T}, Tuple{Int64, Vector{Int64}, Int64}, Tuple{Int64, Vector{Int64}, Int64, T}, Tuple{Int64, Vector{Int64}, Int64, T, Any}, Tuple{Int64, Vector{Int64}, Int64, T, Any, Any}, Tuple{Int64, Vector{Int64}, Int64, T, Any, Any, Any}} where T"><code>RobustNeuralNetworks.LBFN</code></a></li><li><a href="index.html#RobustNeuralNetworks.LipschitzRENParams-Union{Tuple{T}, Tuple{Int64, Int64, Int64, Int64, Number}} where T"><code>RobustNeuralNetworks.LipschitzRENParams</code></a></li><li><a href="index.html#RobustNeuralNetworks.PassiveRENParams-Union{NTuple{4, Int64}, Tuple{T}} where T"><code>RobustNeuralNetworks.PassiveRENParams</code></a></li><li><a href="index.html#RobustNeuralNetworks.REN-Union{Tuple{AbstractRENParams{T}}, Tuple{T}} where T"><code>RobustNeuralNetworks.REN</code></a></li><li><a href="index.html#RobustNeuralNetworks.WrapREN-Union{Tuple{AbstractRENParams{T}}, Tuple{T}} where T"><code>RobustNeuralNetworks.WrapREN</code></a></li><li><a href="index.html#RobustNeuralNetworks.direct_to_explicit"><code>RobustNeuralNetworks.direct_to_explicit</code></a></li><li><a href="index.html#RobustNeuralNetworks.init_states-Tuple{AbstractREN, Any}"><code>RobustNeuralNetworks.init_states</code></a></li><li><a href="index.html#RobustNeuralNetworks.set_output_zero!-Tuple{AbstractREN}"><code>RobustNeuralNetworks.set_output_zero!</code></a></li><li><a href="index.html#RobustNeuralNetworks.update_explicit!-Tuple{WrapREN}"><code>RobustNeuralNetworks.update_explicit!</code></a></li></ul><h2 id="Docstrings"><a class="docs-heading-anchor" href="#Docstrings">Docstrings</a><a id="Docstrings-1"></a><a class="docs-heading-anchor-permalink" href="#Docstrings" title="Permalink"></a></h2><p>Work on the presentation of this a bit....</p><article class="docstring"><header><a class="docstring-binding" id="RobustNeuralNetworks.AbstractLBDN" href="#RobustNeuralNetworks.AbstractLBDN"><code>RobustNeuralNetworks.AbstractLBDN</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">abstract type AbstractLBDN end</code></pre><p>Parameterisation for Lipschitz-bounded deep networks.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/acfr/RobustNeuralNetworks.jl/blob/7159eac541163f052550b1c387da86257300e1f0/src/RobustNeuralNetworks.jl#L33-L37">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="RobustNeuralNetworks.AbstractREN" href="#RobustNeuralNetworks.AbstractREN"><code>RobustNeuralNetworks.AbstractREN</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">abstract type AbstractREN end</code></pre><p>Explicit parameterisation for recurrent equilibrium networks.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/acfr/RobustNeuralNetworks.jl/blob/7159eac541163f052550b1c387da86257300e1f0/src/RobustNeuralNetworks.jl#L26-L30">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="RobustNeuralNetworks.AbstractREN-Tuple{VecOrMat{T} where T, VecOrMat{T} where T}" href="#RobustNeuralNetworks.AbstractREN-Tuple{VecOrMat{T} where T, VecOrMat{T} where T}"><code>RobustNeuralNetworks.AbstractREN</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">(m::AbstractREN)(xt::VecOrMat, ut::VecOrMat)</code></pre><p>Call a REN model given internal states <code>xt</code> and inputs <code>ut</code>. </p><p>If arguments are matrices, each column must be a vector of states or inputs (allows batch simulations).</p><p><strong>Examples</strong></p><p>This example creates a contracting <a href="index.html#RobustNeuralNetworks.REN-Union{Tuple{AbstractRENParams{T}}, Tuple{T}} where T"><code>REN</code></a> using <a href="index.html#RobustNeuralNetworks.ContractingRENParams-Union{NTuple{4, Int64}, Tuple{T}} where T"><code>ContractingRENParams</code></a> and calls the model with some randomly generated inputs. </p><pre><code class="language-julia hljs">using Random
using RobustNeuralNetworks

# Setup
rng = MersenneTwister(42)
batches = 10
nu, nx, nv, ny = 4, 2, 20, 1

# Construct a REN
contracting_ren_ps = ContractingRENParams{Float64}(nu, nx, nv, ny; rng=rng)
ren = REN(contracting_ren_ps)

# Some dummy inputs
x0 = init_states(ren, batches; rng=rng)
u0 = randn(rng, ren.nu, batches)

# Evaluate the REN over one timestep
x1, y1 = ren(x0, u0)

println(round.(y1;digits=2))</code></pre><p>See also <a href="index.html#RobustNeuralNetworks.REN-Union{Tuple{AbstractRENParams{T}}, Tuple{T}} where T"><code>REN</code></a>, <a href="index.html#RobustNeuralNetworks.WrapREN-Union{Tuple{AbstractRENParams{T}}, Tuple{T}} where T"><code>WrapREN</code></a>, and <a href="index.html#RobustNeuralNetworks.DiffREN"><code>DiffREN</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/acfr/RobustNeuralNetworks.jl/blob/7159eac541163f052550b1c387da86257300e1f0/src/Base/ren.jl#L70-L109">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="RobustNeuralNetworks.AbstractRENParams" href="#RobustNeuralNetworks.AbstractRENParams"><code>RobustNeuralNetworks.AbstractRENParams</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">abstract type AbstractRENParams{T} end</code></pre><p>Direct parameterisation for recurrent equilibrium networks.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/acfr/RobustNeuralNetworks.jl/blob/7159eac541163f052550b1c387da86257300e1f0/src/RobustNeuralNetworks.jl#L19-L23">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="RobustNeuralNetworks.ContractingRENParams-Union{NTuple{4, Int64}, Tuple{T}} where T" href="#RobustNeuralNetworks.ContractingRENParams-Union{NTuple{4, Int64}, Tuple{T}} where T"><code>RobustNeuralNetworks.ContractingRENParams</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">ContractingRENParams{T}(nu, nx, nv, ny; &lt;keyword arguments&gt;) where T</code></pre><p>Construct direct parameterisation of a contracting REN.</p><p>The parameters can be used to construct an explicit <a href="index.html#RobustNeuralNetworks.REN-Union{Tuple{AbstractRENParams{T}}, Tuple{T}} where T"><code>REN</code></a> model that has guaranteed, built-in contraction properties.</p><p><strong>Arguments</strong></p><ul><li><code>nu::Int</code>: Number of inputs.</li><li><code>nx::Int</code>: Number of states.</li><li><code>nv::Int</code>: Number of neurons.</li><li><code>ny::Int</code>: Number of outputs.</li></ul><p><strong>Keyword arguments</strong></p><ul><li><p><code>nl=Flux.relu</code>: Static nonlinearity (eg: <code>Flux.relu</code> or <code>Flux.tanh</code>).</p></li><li><p><code>αbar::T=1</code>: Upper bound on the contraction rate with <code>ᾱ ∈ (0,1]</code>.</p></li></ul><p>See <a href="index.html#RobustNeuralNetworks.DirectParams-Union{NTuple{4, Int64}, Tuple{T}} where T"><code>DirectParams</code></a> documentation for arguments <code>init</code>, <code>ϵ</code>, <code>bx_scale</code>, <code>bv_scale</code>, <code>polar_param</code>, <code>D22_zero</code>, <code>rng</code>.</p><p>See also <a href="index.html#RobustNeuralNetworks.GeneralRENParams-Union{Tuple{T}, Tuple{Int64, Int64, Int64, Int64, Matrix{T}, Matrix{T}, Matrix{T}}} where T"><code>GeneralRENParams</code></a>, <a href="index.html#RobustNeuralNetworks.LipschitzRENParams-Union{Tuple{T}, Tuple{Int64, Int64, Int64, Int64, Number}} where T"><code>LipschitzRENParams</code></a>, <a href="index.html#RobustNeuralNetworks.PassiveRENParams-Union{NTuple{4, Int64}, Tuple{T}} where T"><code>PassiveRENParams</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/acfr/RobustNeuralNetworks.jl/blob/7159eac541163f052550b1c387da86257300e1f0/src/ParameterTypes/contracting_ren.jl#L11-L33">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="RobustNeuralNetworks.ContractingRENParams-Union{Tuple{T}, Tuple{Int64, AbstractMatrix{T}, AbstractMatrix{T}, AbstractMatrix{T}, AbstractMatrix{T}}} where T" href="#RobustNeuralNetworks.ContractingRENParams-Union{Tuple{T}, Tuple{Int64, AbstractMatrix{T}, AbstractMatrix{T}, AbstractMatrix{T}, AbstractMatrix{T}}} where T"><code>RobustNeuralNetworks.ContractingRENParams</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">ContractingRENParams(nv, A, B, C, D; ...)</code></pre><p>Alternative constructor for <code>ContractingRENParams</code> that initialises the REN from a <strong>stable</strong> discrete-time linear system with state-space model</p><p class="math-container">\[\begin{align*}
x_{t+1} &amp;= Ax_t + Bu_t \\
y_t &amp;= Cx_t + Du_t.
\end{align*}\]</p><p>TODO: This method may be removed in a later edition of the package. TODO: Make compatible with αbar ≠ 1.0.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/acfr/RobustNeuralNetworks.jl/blob/7159eac541163f052550b1c387da86257300e1f0/src/ParameterTypes/contracting_ren.jl#L59-L74">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="RobustNeuralNetworks.DiffREN" href="#RobustNeuralNetworks.DiffREN"><code>RobustNeuralNetworks.DiffREN</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">mutable struct DiffREN &lt;: AbstractREN</code></pre><p>Wrapper for <code>REN</code> type which automatically re-computes  explicit parameters every time the model is called.</p><p>This is slow, but is compatible with <code>Flux.jl</code></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/acfr/RobustNeuralNetworks.jl/blob/7159eac541163f052550b1c387da86257300e1f0/src/Wrappers/diff_ren.jl#L1-L8">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="RobustNeuralNetworks.DiffREN-Union{Tuple{AbstractRENParams{T}}, Tuple{T}} where T" href="#RobustNeuralNetworks.DiffREN-Union{Tuple{AbstractRENParams{T}}, Tuple{T}} where T"><code>RobustNeuralNetworks.DiffREN</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">DiffREN(ps::AbstractRENParams{T}) where T</code></pre><p>Construct a differentiable REN from its direct parameterisation.</p><p><code>DiffREN</code> is an alternative to <a href="index.html#RobustNeuralNetworks.REN-Union{Tuple{AbstractRENParams{T}}, Tuple{T}} where T"><code>REN</code></a> that computes the explicit parameterisation every time the model is called. This is slow and computationally inefficient. However, it can be used with <a href="http://fluxml.ai/Flux.jl/stable/"><code>Flux.jl</code></a> just like any other <code>Flux</code> model to do machine learning.</p><p>The difference to <a href="index.html#RobustNeuralNetworks.REN-Union{Tuple{AbstractRENParams{T}}, Tuple{T}} where T"><code>REN</code></a> and <a href="index.html#RobustNeuralNetworks.WrapREN-Union{Tuple{AbstractRENParams{T}}, Tuple{T}} where T"><code>WrapREN</code></a> is that the <code>ExplicitParams</code> struct is never stored, so an instance of <code>DiffREN</code> never has to be mutated or re-defined after it is created, even when learnable parameters are updated.</p><p>See also <a href="index.html#RobustNeuralNetworks.REN-Union{Tuple{AbstractRENParams{T}}, Tuple{T}} where T"><code>REN</code></a> and <a href="index.html#RobustNeuralNetworks.WrapREN-Union{Tuple{AbstractRENParams{T}}, Tuple{T}} where T"><code>WrapREN</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/acfr/RobustNeuralNetworks.jl/blob/7159eac541163f052550b1c387da86257300e1f0/src/Wrappers/diff_ren.jl#L19-L29">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="RobustNeuralNetworks.DirectParams-Union{NTuple{4, Int64}, Tuple{T}} where T" href="#RobustNeuralNetworks.DirectParams-Union{NTuple{4, Int64}, Tuple{T}} where T"><code>RobustNeuralNetworks.DirectParams</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">DirectParams{T}(nu, nx, nv; &lt;keyword arguments&gt;) where T</code></pre><p>Construct direct parameterisation for an (acyclic) recurrent equilibrium network.</p><p>This is typically used by higher-level constructors when defining a REN, which take the direct parameterisation and define rules for converting it to an explicit parameterisation. See for example <a href="index.html#RobustNeuralNetworks.GeneralRENParams-Union{Tuple{T}, Tuple{Int64, Int64, Int64, Int64, Matrix{T}, Matrix{T}, Matrix{T}}} where T"><code>GeneralRENParams</code></a>.</p><p><strong>Arguments</strong></p><ul><li><code>nu::Int</code>: Number of inputs.</li><li><code>nx::Int</code>: Number of states.</li><li><code>nv::Int</code>: Number of neurons.</li></ul><p><strong>Keyword arguments</strong></p><ul><li><p><code>init=:random</code>: Initialisation method. Options are:</p><ul><li><code>:random</code>: Random sampling for all parameters.</li><li><code>:cholesky</code>: Compute <code>X</code> with cholesky factorisation of <code>H</code>, sets <code>E,F,P = I</code>.</li></ul></li><li><p><code>polar_param::Bool=true</code>: Use polar parameterisation to construct <code>H</code> matrix from <code>X</code> in REN parameterisation (recommended).</p></li><li><p><code>D22_free::Bool=false</code>: Specify whether to train <code>D22</code> as a free parameter (<code>true</code>), or construct it separately from <code>X3, Y3, Z3</code> (<code>false</code>). Typically use <code>D22_free = true</code> only for a contracting REN.</p></li><li><p><code>D22_zero::Bool=false</code>: Fix <code>D22 = 0</code> to remove any feedthrough.</p></li><li><p><code>bx_scale::T=0</code>: Set scale of initial state bias vector <code>bx</code>.</p></li><li><p><code>bv_scale::T=1</code>: Set scalse of initial neuron input bias vector <code>bv</code>.</p></li><li><p><code>ϵ::T=1e-12</code>: Regularising parameter for positive-definite matrices.</p></li><li><p><code>rng::AbstractRNG=Random.GLOBAL_RNG</code>: rng for model initialisation.</p></li></ul><p>See <a href="https://arxiv.org/abs/2104.05942">Revay et al. (2021)</a> for parameterisation details.</p><p>See also <a href="index.html#RobustNeuralNetworks.GeneralRENParams-Union{Tuple{T}, Tuple{Int64, Int64, Int64, Int64, Matrix{T}, Matrix{T}, Matrix{T}}} where T"><code>GeneralRENParams</code></a>, <a href="index.html#RobustNeuralNetworks.ContractingRENParams-Union{NTuple{4, Int64}, Tuple{T}} where T"><code>ContractingRENParams</code></a>, <a href="index.html#RobustNeuralNetworks.LipschitzRENParams-Union{Tuple{T}, Tuple{Int64, Int64, Int64, Int64, Number}} where T"><code>LipschitzRENParams</code></a>, <a href="index.html#RobustNeuralNetworks.PassiveRENParams-Union{NTuple{4, Int64}, Tuple{T}} where T"><code>PassiveRENParams</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/acfr/RobustNeuralNetworks.jl/blob/7159eac541163f052550b1c387da86257300e1f0/src/Base/direct_params.jl#L22-L58">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="RobustNeuralNetworks.ExplicitParams" href="#RobustNeuralNetworks.ExplicitParams"><code>RobustNeuralNetworks.ExplicitParams</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">mutable struct ExplicitParams{T}</code></pre><p>Explicit REN parameter struct.</p><p>These parameters define a recurrent equilibrium network with model inputs and outputs <span>$u_t, y_t$</span>, neuron inputs and outputs <span>$v_t,w_t$</span>, and states <code>x_t</code>.</p><p class="math-container">\[\begin{equation*}
\begin{bmatrix}
x_{t+1} \\ v_t \\ y_t
\end{bmatrix}
= 
\begin{bmatrix}
A &amp; B_1 &amp; B_2 \\
C_1 &amp; D_{11} &amp; D_{12} \\
C_2 &amp; D_{21} &amp; D_{22} \\
\end{bmatrix}
\begin{bmatrix}
x_t \\ w_t \\ u_t
\end{bmatrix}
+ 
\begin{bmatrix}
b_x \\ b_v \\ b_y
\end{bmatrix}
\end{equation*}\]</p><p>See <a href="https://arxiv.org/abs/2104.05942">Revay et al. (2021)</a> for more details on explicit parameterisations of REN.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/acfr/RobustNeuralNetworks.jl/blob/7159eac541163f052550b1c387da86257300e1f0/src/Base/ren.jl#L1-L30">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="RobustNeuralNetworks.GeneralRENParams-Union{Tuple{T}, Tuple{Int64, Int64, Int64, Int64, Matrix{T}, Matrix{T}, Matrix{T}}} where T" href="#RobustNeuralNetworks.GeneralRENParams-Union{Tuple{T}, Tuple{Int64, Int64, Int64, Int64, Matrix{T}, Matrix{T}, Matrix{T}}} where T"><code>RobustNeuralNetworks.GeneralRENParams</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">GeneralRENParams{T}(nu, nx, nv, ny, Q, S, R; &lt;keyword arguments&gt;) where T</code></pre><p>Construct direct parameterisation of a REN satisfying general behavioural constraints.</p><p>Behavioural constraints are encoded by the matrices <code>Q,S,R</code> in an incremental Integral Quadratic Constraint (IQC). See Equation 4 of <a href="https://arxiv.org/abs/2104.05942">Revay et al. (2021)</a>.</p><p><strong>Arguments</strong></p><ul><li><code>nu::Int</code>: Number of inputs.</li><li><code>nx::Int</code>: Number of states.</li><li><code>nv::Int</code>: Number of neurons.</li><li><code>ny::Int</code>: Number of outputs.</li><li><code>Q::Matrix{T}</code>: IQC weight matrix on model outputs</li><li><code>S::Matrix{T}</code>: IQC coupling matrix on model outputs/inputs</li><li><code>R::Matrix{T}</code>: IQC weight matrix on model outputs</li></ul><p><strong>Keyword arguments</strong></p><ul><li><p><code>nl=Flux.relu</code>: Static nonlinearity (eg: <code>Flux.relu</code> or <code>Flux.tanh</code>).</p></li><li><p><code>αbar::T=1</code>: Upper bound on the contraction rate with <code>ᾱ ∈ (0,1]</code>.</p></li></ul><p>See <a href="index.html#RobustNeuralNetworks.DirectParams-Union{NTuple{4, Int64}, Tuple{T}} where T"><code>DirectParams</code></a> documentation for arguments <code>init</code>, <code>ϵ</code>, <code>bx_scale</code>, <code>bv_scale</code>, <code>polar_param</code>, <code>rng</code>.</p><p>See also <a href="index.html#RobustNeuralNetworks.ContractingRENParams-Union{NTuple{4, Int64}, Tuple{T}} where T"><code>ContractingRENParams</code></a>, <a href="index.html#RobustNeuralNetworks.LipschitzRENParams-Union{Tuple{T}, Tuple{Int64, Int64, Int64, Int64, Number}} where T"><code>LipschitzRENParams</code></a>, <a href="index.html#RobustNeuralNetworks.PassiveRENParams-Union{NTuple{4, Int64}, Tuple{T}} where T"><code>PassiveRENParams</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/acfr/RobustNeuralNetworks.jl/blob/7159eac541163f052550b1c387da86257300e1f0/src/ParameterTypes/general_ren.jl#L14-L39">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="RobustNeuralNetworks.LBFN-Union{Tuple{T}, Tuple{Int64, Vector{Int64}, Int64}, Tuple{Int64, Vector{Int64}, Int64, T}, Tuple{Int64, Vector{Int64}, Int64, T, Any}, Tuple{Int64, Vector{Int64}, Int64, T, Any, Any}, Tuple{Int64, Vector{Int64}, Int64, T, Any, Any, Any}} where T" href="#RobustNeuralNetworks.LBFN-Union{Tuple{T}, Tuple{Int64, Vector{Int64}, Int64}, Tuple{Int64, Vector{Int64}, Int64, T}, Tuple{Int64, Vector{Int64}, Int64, T, Any}, Tuple{Int64, Vector{Int64}, Int64, T, Any, Any}, Tuple{Int64, Vector{Int64}, Int64, T, Any, Any, Any}} where T"><code>RobustNeuralNetworks.LBFN</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">LBFN{T}(nu, nh, ny, γ; ...)</code></pre><p>Constructor for an LBFN with nu inputs, nv outputs, and <code>nh = [nh1, nh2,...]</code> specifying the size of hidden layers. User-imposed Lipschitz bound <code>γ</code> has a default of 1.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/acfr/RobustNeuralNetworks.jl/blob/7159eac541163f052550b1c387da86257300e1f0/src/LBDN/lbfn.jl#L13-L19">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="RobustNeuralNetworks.LipschitzRENParams-Union{Tuple{T}, Tuple{Int64, Int64, Int64, Int64, Number}} where T" href="#RobustNeuralNetworks.LipschitzRENParams-Union{Tuple{T}, Tuple{Int64, Int64, Int64, Int64, Number}} where T"><code>RobustNeuralNetworks.LipschitzRENParams</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">LipschitzRENParams(nu, nx, nv, ny, γ; &lt;keyword arguments&gt;) where T</code></pre><p>Construct direct parameterisation of a REN with a Lipschitz bound of γ.</p><p><strong>Arguments</strong></p><ul><li><code>nu::Int</code>: Number of inputs.</li><li><code>nx::Int</code>: Number of states.</li><li><code>nv::Int</code>: Number of neurons.</li><li><code>ny::Int</code>: Number of outputs.</li><li><code>γ::Number</code>: Lipschitz upper bound.</li></ul><p><strong>Keyword arguments</strong></p><ul><li><p><code>nl=Flux.relu</code>: Static nonlinearity (eg: <code>Flux.relu</code> or <code>Flux.tanh</code>).</p></li><li><p><code>αbar::T=1</code>: Upper bound on the contraction rate with <code>ᾱ ∈ (0,1]</code>.</p></li></ul><p>See <a href="index.html#RobustNeuralNetworks.DirectParams-Union{NTuple{4, Int64}, Tuple{T}} where T"><code>DirectParams</code></a> documentation for arguments <code>init</code>, <code>ϵ</code>, <code>bx_scale</code>, <code>bv_scale</code>, <code>polar_param</code>, <code>D22_zero</code>, <code>rng</code>.</p><p>See also <a href="index.html#RobustNeuralNetworks.GeneralRENParams-Union{Tuple{T}, Tuple{Int64, Int64, Int64, Int64, Matrix{T}, Matrix{T}, Matrix{T}}} where T"><code>GeneralRENParams</code></a>, <a href="index.html#RobustNeuralNetworks.ContractingRENParams-Union{NTuple{4, Int64}, Tuple{T}} where T"><code>ContractingRENParams</code></a>, <a href="index.html#RobustNeuralNetworks.PassiveRENParams-Union{NTuple{4, Int64}, Tuple{T}} where T"><code>PassiveRENParams</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/acfr/RobustNeuralNetworks.jl/blob/7159eac541163f052550b1c387da86257300e1f0/src/ParameterTypes/lipschitz_ren.jl#L12-L33">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="RobustNeuralNetworks.PassiveRENParams-Union{NTuple{4, Int64}, Tuple{T}} where T" href="#RobustNeuralNetworks.PassiveRENParams-Union{NTuple{4, Int64}, Tuple{T}} where T"><code>RobustNeuralNetworks.PassiveRENParams</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">PassiveRENParams{T}(nu, nx, nv, ny; &lt;keyword arguments&gt;) where T</code></pre><p>Construct direct parameterisation of a passive REN.</p><p><strong>Arguments</strong></p><ul><li><code>nu::Int</code>: Number of inputs.</li><li><code>nx::Int</code>: Number of states.</li><li><code>nv::Int</code>: Number of neurons.</li><li><code>ny::Int</code>: Number of outputs.</li></ul><p><strong>Keyword arguments</strong></p><ul><li><p><code>ν::T=0</code>: Passivity parameter. Use ν&gt;0 for incrementally strictly input passive model, and ν == 0 for incrementally passive model. </p></li><li><p><code>nl=Flux.relu</code>: Static nonlinearity (eg: <code>Flux.relu</code> or <code>Flux.tanh</code>).</p></li><li><p><code>αbar::T=1</code>: Upper bound on the contraction rate with <code>ᾱ ∈ (0,1]</code>.</p></li></ul><p>See <a href="index.html#RobustNeuralNetworks.DirectParams-Union{NTuple{4, Int64}, Tuple{T}} where T"><code>DirectParams</code></a> documentation for arguments <code>init</code>, <code>ϵ</code>, <code>bx_scale</code>, <code>bv_scale</code>, <code>polar_param</code>, <code>rng</code>.</p><p>See also <a href="index.html#RobustNeuralNetworks.GeneralRENParams-Union{Tuple{T}, Tuple{Int64, Int64, Int64, Int64, Matrix{T}, Matrix{T}, Matrix{T}}} where T"><code>GeneralRENParams</code></a>, <a href="index.html#RobustNeuralNetworks.ContractingRENParams-Union{NTuple{4, Int64}, Tuple{T}} where T"><code>ContractingRENParams</code></a>, <a href="index.html#RobustNeuralNetworks.LipschitzRENParams-Union{Tuple{T}, Tuple{Int64, Int64, Int64, Int64, Number}} where T"><code>LipschitzRENParams</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/acfr/RobustNeuralNetworks.jl/blob/7159eac541163f052550b1c387da86257300e1f0/src/ParameterTypes/passive_ren.jl#L13-L35">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="RobustNeuralNetworks.REN-Union{Tuple{AbstractRENParams{T}}, Tuple{T}} where T" href="#RobustNeuralNetworks.REN-Union{Tuple{AbstractRENParams{T}}, Tuple{T}} where T"><code>RobustNeuralNetworks.REN</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">REN(ps::AbstractRENParams{T}) where T</code></pre><p>Construct a REN from its direct parameterisation.</p><p>This constructor takes a direct parameterisation of REN (eg: a <a href="index.html#RobustNeuralNetworks.GeneralRENParams-Union{Tuple{T}, Tuple{Int64, Int64, Int64, Int64, Matrix{T}, Matrix{T}, Matrix{T}}} where T"><code>GeneralRENParams</code></a> instance) and converts it to a <strong>callable</strong> explicit parameterisation of the REN.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/acfr/RobustNeuralNetworks.jl/blob/7159eac541163f052550b1c387da86257300e1f0/src/Base/ren.jl#L56-L64">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="RobustNeuralNetworks.WrapREN-Union{Tuple{AbstractRENParams{T}}, Tuple{T}} where T" href="#RobustNeuralNetworks.WrapREN-Union{Tuple{AbstractRENParams{T}}, Tuple{T}} where T"><code>RobustNeuralNetworks.WrapREN</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">WrapREN(ps::AbstractRENParams{T}) where T</code></pre><p>Construct REN wrapper from its direct parameterisation.</p><p><code>WrapREN</code> is an alternative to <a href="index.html#RobustNeuralNetworks.REN-Union{Tuple{AbstractRENParams{T}}, Tuple{T}} where T"><code>REN</code></a> that stores the <a href="index.html#RobustNeuralNetworks.AbstractRENParams"><code>AbstractRENParams</code></a> and <a href="index.html#RobustNeuralNetworks.ExplicitParams"><code>ExplicitParams</code></a> within the same object. This means that a new <code>REN</code> object does not have to be created each time the parameters are updated. Explicit REN parameters must be updated by the user if the direct parameters have changed.</p><p>Note that <code>WrapREN</code> cannot be used with <a href="http://fluxml.ai/Flux.jl/stable/"><code>Flux.jl</code></a>, since it relies on mutating the <code>WrapREN</code> instance.</p><p><strong>Examples</strong></p><p>In this example, we create a REN satisfying some generic behavioural constraints and demonstrate how to update the REN wrapper if model parameters are changed.</p><pre><code class="language-julia hljs">using LinearAlgebra
using Random
using RobustNeuralNetworks

# Setup
rng = MersenneTwister(42)
batches = 10
nu, nx, nv, ny = 4, 10, 20, 2

Q = Matrix{Float64}(-I(ny))
R = 0.1^2 * Matrix{Float64}(I(nu))
S = zeros(Float64, nu, ny)

# Construct a REN
ren_ps = GeneralRENParams{Float64}(nu, nx, nv, ny, Q, S, R; rng=rng)
ren = WrapREN(ren_ps)

# Some dummy inputs
x0 = init_states(ren, batches; rng=rng)
u0 = randn(rng, ren.nu, batches)

# Evaluate the REN over one timestep
x1, y1 = ren(x0, u0) 

# Update the model after changing a parameter
ren.params.direct.B2 .*= rand(rng, size(ren.params.direct.B2)...)
update_explicit!(ren)

println(round(ren.explicit.B2[1];digits=4))</code></pre><p>See also <a href="index.html#RobustNeuralNetworks.REN-Union{Tuple{AbstractRENParams{T}}, Tuple{T}} where T"><code>REN</code></a> and <a href="index.html#RobustNeuralNetworks.DiffREN"><code>DiffREN</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/acfr/RobustNeuralNetworks.jl/blob/7159eac541163f052550b1c387da86257300e1f0/src/Wrappers/wrap_ren.jl#L12-L62">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="RobustNeuralNetworks.direct_to_explicit" href="#RobustNeuralNetworks.direct_to_explicit"><code>RobustNeuralNetworks.direct_to_explicit</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">direct_to_explicit(ps::AbstractRENParams, return_h=false) where T</code></pre><p>Convert direct parameterisation of RENs to explicit parameterisation.</p><p>Uses the parameterisation encoded in <code>ps</code> to construct an <a href="index.html#RobustNeuralNetworks.ExplicitParams"><code>ExplicitParams</code></a> object that naturally satisfies a set of user-defined behavioural constraints.</p><p><strong>Arguments</strong></p><ul><li><p><code>ps::AbstractRENParams</code>: Direct parameterisation with behavioural constraints to convert to an explicit parameterisation of REN (eg: <a href="index.html#RobustNeuralNetworks.GeneralRENParams-Union{Tuple{T}, Tuple{Int64, Int64, Int64, Int64, Matrix{T}, Matrix{T}, Matrix{T}}} where T"><code>GeneralRENParams</code></a>).</p></li><li><p><code>return_h::Bool=false</code>: Whether to return the H-matrix directly (see <a href="https://arxiv.org/abs/2104.05942">Revay et al. (2021)</a>). Useful for debugging or model analysis. If <code>false</code>, function returns an object of type <code>ExplicitParams{T}</code>. </p></li></ul><p>See also <a href="index.html#RobustNeuralNetworks.GeneralRENParams-Union{Tuple{T}, Tuple{Int64, Int64, Int64, Int64, Matrix{T}, Matrix{T}, Matrix{T}}} where T"><code>GeneralRENParams</code></a>, <a href="index.html#RobustNeuralNetworks.ContractingRENParams-Union{NTuple{4, Int64}, Tuple{T}} where T"><code>ContractingRENParams</code></a>, <a href="index.html#RobustNeuralNetworks.LipschitzRENParams-Union{Tuple{T}, Tuple{Int64, Int64, Int64, Int64, Number}} where T"><code>LipschitzRENParams</code></a>, <a href="index.html#RobustNeuralNetworks.PassiveRENParams-Union{NTuple{4, Int64}, Tuple{T}} where T"><code>PassiveRENParams</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/acfr/RobustNeuralNetworks.jl/blob/7159eac541163f052550b1c387da86257300e1f0/src/ParameterTypes/utils.jl#L1-L15">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="RobustNeuralNetworks.init_states-Tuple{AbstractREN, Any}" href="#RobustNeuralNetworks.init_states-Tuple{AbstractREN, Any}"><code>RobustNeuralNetworks.init_states</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">init_states(m::AbstractREN, nbatches; rng=nothing)</code></pre><p>Return matrix of (nbatches) state vectors of a REN initialised as zeros.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/acfr/RobustNeuralNetworks.jl/blob/7159eac541163f052550b1c387da86257300e1f0/src/Base/ren.jl#L120-L124">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="RobustNeuralNetworks.set_output_zero!-Tuple{AbstractREN}" href="#RobustNeuralNetworks.set_output_zero!-Tuple{AbstractREN}"><code>RobustNeuralNetworks.set_output_zero!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">set_output_zero!(m::AbstractREN)</code></pre><p>Set output map of a REN to zero.</p><p>If the resulting model is called with <code>x1,y = ren(x,u)</code> then <code>y = 0</code> for any <code>x</code> and <code>u</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/acfr/RobustNeuralNetworks.jl/blob/7159eac541163f052550b1c387da86257300e1f0/src/Base/ren.jl#L133-L139">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="RobustNeuralNetworks.update_explicit!-Tuple{WrapREN}" href="#RobustNeuralNetworks.update_explicit!-Tuple{WrapREN}"><code>RobustNeuralNetworks.update_explicit!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">update_explicit!(m::WrapREN)</code></pre><p>Update explicit model in <code>WrapREN</code> using the current direct parameters.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/acfr/RobustNeuralNetworks.jl/blob/7159eac541163f052550b1c387da86257300e1f0/src/Wrappers/wrap_ren.jl#L68-L72">source</a></section></article><h2 id="TODO:"><a class="docs-heading-anchor" href="#TODO:">TODO:</a><a id="TODO:-1"></a><a class="docs-heading-anchor-permalink" href="#TODO:" title="Permalink"></a></h2><ul><li>Add a logo</li><li>Fill out this main documentation page</li><li>See <a href="https://juliacontrol.github.io/ControlSystems.jl/stable/">ControlSystems.jl</a> for a good example of how to structure this page.</li></ul></article><nav class="docs-footer"><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.24 on <span class="colophon-date" title="Tuesday 4 April 2023 07:54">Tuesday 4 April 2023</span>. Using Julia version 1.6.7.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
