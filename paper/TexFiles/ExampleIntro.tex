This section guides the reader through a set of examples to demonstrate how to use \verb|RobustNeuralnetworks.jl| for machine learning in Julia. We will consider three examples: image classification, reinforcement learning, and nonlinear state-observer design. These examples will provide further insight into the benefits of using robust models and the reasoning behind key design decisions made in the development of the package.

We use \verb|relu| activation functions in all examples, but other choices of activation function (e.g: \verb|tanh|) are equally valid. We note that any activation function used in a REN or LBDN must have a maximum slope of 1.0, as outlined in \cite{Revay++2021b,Wang+Manchester2023}. For more examples with RENs and LBDNs, please see the package documentation\footnote{\url{https://acfr.github.io/RobustNeuralNetworks.jl/}}.