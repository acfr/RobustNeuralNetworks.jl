<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Package Overview · RobustNeuralNetworks.jl</title><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.svg" alt="RobustNeuralNetworks.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">RobustNeuralNetworks.jl</a></span></div><form class="docs-search" action="../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><span class="tocitem">Introduction</span><ul><li><a class="tocitem" href="../getting_started/">Getting Started</a></li><li class="is-active"><a class="tocitem" href>Package Overview</a><ul class="internal"><li><a class="tocitem" href="#What-are-RENs-and-LBDNs?"><span>What are RENs and LBDNs?</span></a></li><li><a class="tocitem" href="#Direct-and-explicit-parameterisations"><span>Direct &amp; explicit parameterisations</span></a></li><li><a class="tocitem" href="#Onto-the-GPU"><span>Onto the GPU</span></a></li><li><a class="tocitem" href="#Robustness-metrics-and-IQCs"><span>Robustness metrics and IQCs</span></a></li></ul></li><li><a class="tocitem" href="../developing/">Contributing to the Package</a></li></ul></li><li><span class="tocitem">Examples</span><ul><li><a class="tocitem" href="../../examples/lbdn_curvefit/">Fitting a Curve</a></li><li><a class="tocitem" href="../../examples/lbdn_mnist/">Image Classification</a></li><li><a class="tocitem" href="../../examples/rl/">Reinforcement Learning</a></li><li><a class="tocitem" href="../../examples/box_obsv/">Observer Design</a></li><li><a class="tocitem" href="../../examples/echo_ren/">(Convex) Nonlinear Control</a></li></ul></li><li><span class="tocitem">Library</span><ul><li><a class="tocitem" href="../../lib/models/">Model Wrappers</a></li><li><a class="tocitem" href="../../lib/model_params/">Model Parameterisations</a></li><li><a class="tocitem" href="../../lib/functions/">Functions</a></li></ul></li><li><a class="tocitem" href="../../api/">API</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Introduction</a></li><li class="is-active"><a href>Package Overview</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Package Overview</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/acfr/RobustNeuralNetworks.jl/blob/main/docs/src/introduction/package_overview.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Package-Overview"><a class="docs-heading-anchor" href="#Package-Overview">Package Overview</a><a id="Package-Overview-1"></a><a class="docs-heading-anchor-permalink" href="#Package-Overview" title="Permalink"></a></h1><p><code>RobustNeuralNetwork.jl</code> contains two classes of neural network models: Recurrent Equilibrium Networks (RENs) and Lipschitz-Bounded Deep Networks (LBDNs). This page gives a brief overview of the two model architectures and how they are parameterised to automatically satisfy robustness certificates. We also provide some background on the different types of robustness metrics used to construct the models.</p><h2 id="What-are-RENs-and-LBDNs?"><a class="docs-heading-anchor" href="#What-are-RENs-and-LBDNs?">What are RENs and LBDNs?</a><a id="What-are-RENs-and-LBDNs?-1"></a><a class="docs-heading-anchor-permalink" href="#What-are-RENs-and-LBDNs?" title="Permalink"></a></h2><p>A <em>Recurrent Equilibrium Network</em> (REN) is a linear system in feedback with a nonlinear activation function. Denote <span>$x_t \in \mathbb{R}^{n_x}$</span> as the internal states of the system, <span>$u_t \in\mathbb{R}^{n_u}$</span> as its inputs, and <span>$y_t \in \mathbb{R}^{n_u}$</span> as its outputs. Mathematically, a REN can be represented as</p><p class="math-container">\[\begin{aligned}
\begin{bmatrix}
x_{t+1} \\ v_t \\ y_t
\end{bmatrix}&amp;=
\overset{W}{\overbrace{
		\left[
		\begin{array}{c|cc}
		A &amp; B_1 &amp; B_2 \\ \hline 
		C_{1} &amp; D_{11} &amp; D_{12} \\
		C_{2} &amp; D_{21} &amp; D_{22}
		\end{array} 
		\right]
}}
\begin{bmatrix}
x_t \\ w_t \\ u_t
\end{bmatrix}+
\overset{b}{\overbrace{
		\begin{bmatrix}
		b_x \\ b_v \\ b_y
		\end{bmatrix}
}}, \\
w_t=\sigma(&amp;v_t):=\begin{bmatrix}
\sigma(v_{t}^1) &amp; \sigma(v_{t}^2) &amp; \cdots &amp; \sigma(v_{t}^q)
\end{bmatrix}^\top, 
\end{aligned}\]</p><p>where <span>$v_t, w_t \in \mathbb{R}^{n_v}$</span> are the inputs and outputs of neurons and <span>$\sigma$</span> is the activation function. Graphically, this is equivalent to the following, where the linear (actually affine) system <span>$G$</span> represents the first equation above.</p><p align="center"> <object type="image/png" data=../../assets/ren.png width="35%"></object> </p><p>A <em>Lipschitz-Bounded Deep Network</em> (LBDN) is a (memoryless) deep neural network model with a built-in upper-bound on its Lipschitz constant. Although it is a specialisation of a REN with a state dimension of <span>$n_x = 0$</span>, we use this simplification to construct LBDN models completely differently to RENs. We construct LBDNs as <span>$L$</span>-layer feed-forward networks, much like <a href="https://en.wikipedia.org/wiki/Multilayer_perceptron">MLPs</a> or <a href="https://en.wikipedia.org/wiki/Convolutional_neural_network">CNNs</a>, described by the following recursive equations.</p><p class="math-container">\[\begin{aligned}
z_0 &amp;= x \\
z_{k+1} &amp;= \sigma(W_k z_k + b_k), \quad k = 0, \ldots, L-1 \\
y &amp;= W_L z_L + b_L
\end{aligned}\]</p><p>See <a href="https://ieeexplore.ieee.org/document/10179161">Revay, Wang &amp; Manchester (2021)</a> and <a href="https://proceedings.mlr.press/v202/wang23v.html">Wang &amp; Manchester (2023)</a> for more details on RENs and LBDNs, respectively.</p><div class="admonition is-info"><header class="admonition-header">Acyclic REN models</header><div class="admonition-body"><p><a href="https://ieeexplore.ieee.org/document/10179161">Revay, Wang &amp; Manchester (2021)</a> make special mention of &quot;acyclic&quot; RENs, which have a lower-triangular <span>$D_{11}$</span>. These are significantly more efficient to evaluate and train than a REN with dense <span>$D_{11},$</span> and they perform similarly. All RENs in <code>RobustNeuralNetworks.jl</code> are therefore acyclic RENs.</p></div></div><h2 id="Direct-and-explicit-parameterisations"><a class="docs-heading-anchor" href="#Direct-and-explicit-parameterisations">Direct &amp; explicit parameterisations</a><a id="Direct-and-explicit-parameterisations-1"></a><a class="docs-heading-anchor-permalink" href="#Direct-and-explicit-parameterisations" title="Permalink"></a></h2><p>The key advantage of the models in <code>RobustNeuralNetworks.jl</code> is that they <em>naturally</em> satisfy a set of user-defined robustness constraints (outlined in <a href="#Robustness-metrics-and-IQCs">Robustness metrics and IQCs</a>). I.e., robustness is guaranteed by construction. There is no need to impose additional (possibly computationally-expensive) constraints while training a REN or an LBDN. One can simply use unconstrained optimisation methods like gradient descent and be sure that the final model will satisfy the robustness requirements.</p><p>We achieve this by constructing the weight matrices and bias vectors in our models to automatically satisfy some specific linear matrix inequalities (see <a href="https://ieeexplore.ieee.org/document/10179161">Revay, Wang &amp; Manchester (2021)</a> for details). The <em>learnable parameters</em> of a model are a set of free variables <span>$\theta \in \mathbb{R}^N$</span> which are completely unconstrained. When the set of learnable parameters is exactly <span>$\mathbb{R}^N$</span> like this, we call it a <strong>direct parameterisation</strong>. The equations above describe the <strong>explicit parameterisation</strong> of RENs and LBDNs: a callable model that we can evaluate on data. For a REN, the <em>explicit parameters</em> are <span>$\bar{\theta} = [W, b]$</span>, and for an LBDN they are <span>$\bar{\theta} = [W_0, b_0, \ldots, W_L, b_L]$</span>.</p><p>RENs are defined by two abstract types in <code>RobustNeuralNetworks.jl</code>. Subtypes of <code>AbstractRENParams</code> hold all the information required to directly parameterise a REN satisfying some robustness properties. For example, to initialise the direct parameters of a <em>contracting</em> REN with 1 input, 10 states, 20 neurons, 1 output, and a <code>relu</code> activation function, we use the following. The direct parameters <span>$\theta$</span> are stored in <code>model_ps.direct</code>. </p><pre><code class="language-julia hljs">using RobustNeuralNetworks

nu, nx, nv, ny = 1, 10, 20, 1
model_params = ContractingRENParams{Float64}(nu, nx, nv, ny)

typeof(model_params) &lt;: AbstractRENParams</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">true</code></pre><p>Subtypes of <a href="../../lib/models/#RobustNeuralNetworks.AbstractREN"><code>AbstractREN</code></a> represent RENs in their explicit form so that they can be called and evaluated. The conversion from the direct to explicit parameters <span>$\theta \mapsto \bar{\theta}$</span> is performed when the REN is constructed.</p><pre><code class="language-julia hljs">model = REN(model_params)

println(typeof(model) &lt;: AbstractREN)
println(typeof(model_params.direct)) 		# Access direct params</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">true
DirectRENParams{Float64}</code></pre><p>The same is true for <a href="../../lib/model_params/#RobustNeuralNetworks.AbstractLBDNParams"><code>AbstractLBDNParams</code></a> and <a href="../../lib/models/#RobustNeuralNetworks.AbstractLBDN"><code>AbstractLBDN</code></a> regarding LBDN models.</p><h3 id="Types-of-direct-parameterisations"><a class="docs-heading-anchor" href="#Types-of-direct-parameterisations">Types of direct parameterisations</a><a id="Types-of-direct-parameterisations-1"></a><a class="docs-heading-anchor-permalink" href="#Types-of-direct-parameterisations" title="Permalink"></a></h3><p>There are currently four REN parameterisations implemented in this package:</p><ul><li><p><a href="../../lib/model_params/#RobustNeuralNetworks.ContractingRENParams"><code>ContractingRENParams</code></a> parameterises RENs with a user-defined upper bound on the contraction rate.</p></li><li><p><a href="../../lib/model_params/#RobustNeuralNetworks.LipschitzRENParams"><code>LipschitzRENParams</code></a> parameterises RENs with a user-defined (or learnable) Lipschitz bound of <span>$\gamma \in (0,\infty)$</span>.</p></li><li><p><a href="../../lib/model_params/#RobustNeuralNetworks.PassiveRENParams"><code>PassiveRENParams</code></a> parameterises input/output passive RENs with user-tunable passivity parameter <span>$\nu \ge 0$</span>.</p></li><li><p><a href="../../lib/model_params/#RobustNeuralNetworks.GeneralRENParams"><code>GeneralRENParams</code></a> parameterises RENs satisfying some general behavioural constraints defined by an Integral Quadratic Constraint (IQC) with parameters (Q,S,R).</p></li></ul><p>Similarly, subtypes of <a href="../../lib/model_params/#RobustNeuralNetworks.AbstractLBDNParams"><code>AbstractLBDNParams</code></a> define the direct parameterisation of LBDNs. There is currently only one version implemented in <code>RobustNeuralNetworks.jl</code>:</p><ul><li><a href="../../lib/model_params/#RobustNeuralNetworks.DenseLBDNParams"><code>DenseLBDNParams</code></a> parameterise dense (fully-connected) LBDNs. A dense LBDN is effectively a Lipschitz-bounded <a href="https://fluxml.ai/Flux.jl/stable/models/layers/#Flux.Dense"><code>Flux.Dense</code></a> network.</li></ul><p>See <a href="#Robustness-metrics-and-IQCs">Robustness metrics and IQCs</a> for an explanation of these robustness metrics. We intend on adding <code>ConvolutionalLBDNParams</code> to parameterise convolutional LBDNs in future iterations of the package (see <a href="https://proceedings.mlr.press/v202/wang23v.html">Wang &amp; Manchester (2023)</a>).</p><h3 id="Explicit-model-wrappers"><a class="docs-heading-anchor" href="#Explicit-model-wrappers">Explicit model wrappers</a><a id="Explicit-model-wrappers-1"></a><a class="docs-heading-anchor-permalink" href="#Explicit-model-wrappers" title="Permalink"></a></h3><p>When training a REN or LBDN, we learn and update the direct parameters <span>$\theta$</span> and convert them to the explicit parameters <span>$\bar{\theta}$</span> only for model evaluation. The main constructors for explicit models are <a href="../../lib/models/#RobustNeuralNetworks.REN"><code>REN</code></a> and <a href="../../lib/models/#RobustNeuralNetworks.LBDN"><code>LBDN</code></a>.</p><p>Users familiar with <a href="https://fluxml.ai/"><code>Flux.jl</code></a> will be used to creating a model once and then training it on their data. The typical workflow is as follows.</p><pre><code class="language-julia hljs">using Flux
using Random

# Define a model and a loss function
model = Chain(Flux.Dense(1 =&gt; 10, Flux.relu), Flux.Dense(10 =&gt; 1, Flux.relu))
loss(model, x, y) = Flux.mse(model(x), y)

# Set up some dummy training data
batches = 20
xs, ys = rand(Float32,1,batches), rand(Float32,1,batches)
data = [(xs, ys)]

# Train the model for 50 epochs
opt_state = Flux.setup(Adam(0.01), model)
for _ in 1:50
    Flux.train!(loss, model, data, opt_state)
end</code></pre><p>When training a model constructed from <a href="../../lib/models/#RobustNeuralNetworks.REN"><code>REN</code></a> or <a href="../../lib/models/#RobustNeuralNetworks.LBDN"><code>LBDN</code></a>, we need to back-propagate through the mapping from direct (learnable) parameters to the explicit model. We must therefore include the model construction as part of the loss function. If we do not, then the auto-differentiation engine has no knowledge of how the model parameters affect the loss, and will return zero gradients. Here is an example with an <a href="../../lib/models/#RobustNeuralNetworks.LBDN"><code>LBDN</code></a>, where the <code>model</code> is defined by the direct parameterisation stored in <code>model_params</code>.</p><pre><code class="language-julia hljs">using Flux
using Random
using RobustNeuralNetworks

# Define a model parameterisation and a loss function
model_params = DenseLBDNParams{Float64}(1, [10], 1)
function loss(model_params, x, y)
    model = LBDN(model_params)
    Flux.mse(model(x), y)
end

# Set up some dummy training data
batches = 20
xs, ys = rand(1,batches), rand(1,batches)
data = [(xs, ys)]

# Train the model for 50 epochs
opt_state = Flux.setup(Adam(0.01), model_params)
for _ in 1:50
    Flux.train!(loss, model_params, data, opt_state)
end</code></pre><h3 id="Separating-parameters-and-models-is-efficient"><a class="docs-heading-anchor" href="#Separating-parameters-and-models-is-efficient">Separating parameters and models is efficient</a><a id="Separating-parameters-and-models-is-efficient-1"></a><a class="docs-heading-anchor-permalink" href="#Separating-parameters-and-models-is-efficient" title="Permalink"></a></h3><p>For the sake of convenience, we have included the model wrappers <a href="../../lib/models/#RobustNeuralNetworks.DiffREN"><code>DiffREN</code></a>, <a href="../../lib/models/#RobustNeuralNetworks.DiffLBDN"><code>DiffLBDN</code></a>, and <a href="../../lib/models/#RobustNeuralNetworks.SandwichFC"><code>SandwichFC</code></a> as alternatives to <a href="../../lib/models/#RobustNeuralNetworks.REN"><code>REN</code></a>, and <a href="../../lib/models/#RobustNeuralNetworks.LBDN"><code>LBDN</code></a>, respectively. These wrappers compute the explicit parameters each time the model is called rather than just once when they are constructed. Any model created with these wrappers can therefore be used exactly the same way as a regular <code>Flux.jl</code> model, and there is no need for model construction in the loss function. One can simply replace the definition of the <code>Flux.Chain</code> model in the demo cell above with</p><pre><code class="language-julia hljs">model_params = DenseLBDNParams{Float64}(1, [10], 1; nl=relu)
model = DiffLBDN(model_params)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">DiffLBDN{Float64, 1}(NNlib.relu, 1, (10,), 1, DenseLBDNParams{Float64, 1}(NNlib.relu, 1, (10,), 1, DirectLBDNParams{Float64, 2, 1}(([0.24835091829299927 -0.08171013742685318 … 0.347101628780365 0.5176975727081299; 0.5515995621681213 0.21881547570228577 … -0.4213991165161133 0.30059459805488586; … ; 0.4402223527431488 -0.23861058056354523 … 0.1189761608839035 -0.24195866286754608; -0.5564591288566589 -0.31914159655570984 … -0.1932692527770996 -0.2141687422990799], [0.5063624382019043; -0.22739160060882568; … ; 0.7848535180091858; -0.5930105447769165;;]), ([3.471668004213578], [1.3122138882047452]), ([0.25508272647857666, 0.06097019091248512, 0.5367322564125061, 0.034377679228782654, -0.237176313996315, 0.009433419443666935, -0.7727654576301575, 0.2971942722797394, -0.08366859704256058, -0.568020224571228],), ([0.33250781893730164, -0.38258787989616394, 0.5833813548088074, -0.1544439196586609, 0.3978036344051361, -0.35216549038887024, -0.3218485713005066, 0.3884829878807068, 0.5860629677772522, -0.10062595456838608], [0.7601862549781799]), [0.0], false)))</code></pre><p>and train the LBDN just like any other <code>Flux.jl</code> model. We use these wrappers in many of the examples (eg: <a href="../../examples/lbdn_mnist/#Image-Classification-with-LBDN">Image Classification with LBDN</a>).</p><p>The reason we nominally keep the <code>model_params</code> and <code>model</code> separate with <a href="../../lib/models/#RobustNeuralNetworks.REN"><code>REN</code></a> and <a href="../../lib/models/#RobustNeuralNetworks.LBDN"><code>LBDN</code></a> is to offer flexibility. The computational bottleneck in training a REN or LBDN is converting from the direct to explicit parameters (mapping <span>$\theta \mapsto \bar{\theta}$</span>). Direct parameters are stored in <code>model_params</code>, while explicit parameters are computed when the <code>model</code> is created and are stored within it. We can see this from our earlier example with the contracting REN:</p><pre><code class="language-julia hljs">println(typeof(model_params.direct))
println(typeof(model.explicit))</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">DirectRENParams{Float64}
ExplicitRENParams{Float64}</code></pre><p>In some applications (eg: reinforcement learning), a model is called many times with the same explicit parameters <span>$\bar{\theta}$</span> before its learnable parameters <span>$\theta$</span> are updated. It&#39;s therefore significantly efficient to store the explicit parameters, use them many times, and then update them only when the learnable parameters change. We can&#39;t store the direct and explicit parameters in the same <code>model</code> object since auto-differentiation in <a href="https://fluxml.ai/Zygote.jl/stable/limitations/"><code>Flux.jl</code> does not permit array mutation</a>. Instead, we separate the two.</p><div class="admonition is-info"><header class="admonition-header">Which wrapper should I use?</header><div class="admonition-body"><p>The model wrappers <a href="../../lib/models/#RobustNeuralNetworks.DiffREN"><code>DiffREN</code></a>, <a href="../../lib/models/#RobustNeuralNetworks.DiffLBDN"><code>DiffLBDN</code></a>, and <a href="../../lib/models/#RobustNeuralNetworks.SandwichFC"><code>SandwichFC</code></a>  re-compute the explicit parameters every time the model is called. In applications where the learnable parameters are updated after one model call (eg: image classification), it is often more convenient and equally fast to use these wrappers.</p><p>In applications where the model is called many times before updating it (eg: reinforcement learning), use <a href="../../lib/models/#RobustNeuralNetworks.REN"><code>REN</code></a> or <a href="../../lib/models/#RobustNeuralNetworks.LBDN"><code>LBDN</code></a>. They compute the explicit model when constructed and store it for later use, making them more efficient.</p></div></div><p>See <a href="../../examples/rl/#Can&#39;t-I-just-use-DiffLBDN?">Can&#39;t I just use <code>DiffLBDN</code>?</a> in <a href="../../examples/rl/#Reinforcement-Learning-with-LBDN">Reinforcement Learning with LBDN</a> for a demonstration of this trade-off.</p><h2 id="Onto-the-GPU"><a class="docs-heading-anchor" href="#Onto-the-GPU">Onto the GPU</a><a id="Onto-the-GPU-1"></a><a class="docs-heading-anchor-permalink" href="#Onto-the-GPU" title="Permalink"></a></h2><p>If you have a GPU on your machine, then you&#39;re in luck. All models in <code>RobustNeuralNetworks.jl</code> can be loaded onto the GPU for training and evaluation in exactly the same way as any other <code>Flux.jl</code> model. To adapt our example from <a href="#Explicit-model-wrappers">Explicit model wrappers</a> to run on the GPU, we would do the following.</p><pre><code class="language-julia hljs">using CUDA

model_params = model_params |&gt; gpu
data = data |&gt; gpu

opt_state = Flux.setup(Adam(0.01), model_params)
for _ in 1:50
    Flux.train!(loss, model_params, data, opt_state)
end</code></pre><p>An example of training a <a href="../../lib/models/#RobustNeuralNetworks.DiffLBDN"><code>DiffLBDN</code></a> on the GPU is provided in <a href="../../examples/lbdn_mnist/#Image-Classification-with-LBDN">Image Classification with LBDN</a>. See <a href="https://fluxml.ai/Flux.jl/stable/gpu/"><code>Flux.jl</code>&#39;s GPU support page</a> for more information on training models with different GPU backends.</p><h2 id="Robustness-metrics-and-IQCs"><a class="docs-heading-anchor" href="#Robustness-metrics-and-IQCs">Robustness metrics and IQCs</a><a id="Robustness-metrics-and-IQCs-1"></a><a class="docs-heading-anchor-permalink" href="#Robustness-metrics-and-IQCs" title="Permalink"></a></h2><p>All neural network models in <code>RobustNeuralNetworks.jl</code> are designed to satisfy a set of user-defined robustness constraints. There are a number of different robustness criteria which our RENs can satisfy. Some relate to the internal dynamics of the model, others relate to the input-output map. LBDNs are less general, and are specifically constructed to satisfy Lipschitz bounds. See the section on <a href="#Lipschitz-bounds-(smoothness)">Lipschitz bounds (smoothness)</a> below.</p><h3 id="Contracting-systems"><a class="docs-heading-anchor" href="#Contracting-systems">Contracting systems</a><a id="Contracting-systems-1"></a><a class="docs-heading-anchor-permalink" href="#Contracting-systems" title="Permalink"></a></h3><p>First and foremost, all of our RENs are <em>contracting systems</em>. This means that they exponentially &quot;forget&quot; initial conditions. If the system starts at two different initial conditions but is given the same inputs, the internal states will converge over time. See below for an example of a contracting REN with a single internal state. The code used to generate this figure can be found <a href="https://github.com/acfr/RobustNeuralNetworks.jl/blob/main/examples/src/contracting_ren.jl">here</a>.</p><p align="center"> <object type="image/svg+xml" data=../../assets/contracting_ren.svg width="50%"></object> </p><h3 id="Integral-quadratic-constraints"><a class="docs-heading-anchor" href="#Integral-quadratic-constraints">Integral quadratic constraints</a><a id="Integral-quadratic-constraints-1"></a><a class="docs-heading-anchor-permalink" href="#Integral-quadratic-constraints" title="Permalink"></a></h3><p>We define additional robustness criteria on the input/output map of our RENs with <em>incremental integral quadratic constraints</em> (IQCs). Suppose we have a model <span>$\mathcal{M}$</span> starting at two different initial conditions <span>$a,b$</span> with two different input signals <span>$u, v$</span>, and consider their corresponding output trajectories <span>$y^a = \mathcal{M}_a(u)$</span> and <span>$y^b = \mathcal{M}_b(v).$</span> The model <span>$\mathcal{M}$</span> satisfies the IQC defined by matrices <span>$(Q, S, R)$</span> if</p><p class="math-container">\[\sum_{t=0}^T
\begin{bmatrix}
y^a_t - y^b_t \\ u_t - v_t
\end{bmatrix}^\top
\begin{bmatrix}
Q &amp; S^\top \\ S &amp; R
\end{bmatrix}
\begin{bmatrix}
y^a_t - y^b_t \\ u_t - v_t
\end{bmatrix} 
\ge -d(a,b)
\quad \forall \, T\]</p><p>for some function <span>$d(a,b) \ge 0$</span> with <span>$d(a,a) = 0$</span>, where <span>$0 \preceq Q \in \mathbb{R}^{n_y\times n_y}$</span>, <span>$S\in\mathbb{R}^{n_u\times n_y},$</span> <span>$R=R^\top \in \mathbb{R}^{n_u\times n_u}.$</span> </p><p>In general, the IQC matrices <span>$(Q,S,R)$</span> can be chosen (or optimised) to meet a range of performance criteria. There are a few special cases that are worth noting.</p><h4 id="Lipschitz-bounds-(smoothness)"><a class="docs-heading-anchor" href="#Lipschitz-bounds-(smoothness)">Lipschitz bounds (smoothness)</a><a id="Lipschitz-bounds-(smoothness)-1"></a><a class="docs-heading-anchor-permalink" href="#Lipschitz-bounds-(smoothness)" title="Permalink"></a></h4><p>If <span>$Q = -\frac{1}{\gamma}I$</span>, <span>$R = \gamma I$</span>, <span>$S = 0$</span>, the model <span>$\mathcal{M}$</span> satisfies a Lipschitz bound (incremental <span>$\ell^2$</span>-gain bound) of <span>$\gamma$</span>.</p><p class="math-container">\[\|\mathcal{M}_a(u) - \mathcal{M}_b(v)\|_T \le \gamma \|u - v\|_T\]</p><p>Qualitatively, the Lipschitz bound is a measure of how smooth the network is. If the Lipschitz bound <span>$\gamma$</span> is small, then small changes in the inputs <span>$u,v$</span> will lead to small changes in the model output. If <span>$\gamma$</span> is large, then the model output might change significantly for even small changes to the inputs. This can make the model more sensitive to noise, adversarial attacks, and other input disturbances.</p><p>As the name suggests, the LBDN models are all constructed to have a user-tunable Lipschitz bound.</p><h4 id="Incremental-passivity"><a class="docs-heading-anchor" href="#Incremental-passivity">Incremental passivity</a><a id="Incremental-passivity-1"></a><a class="docs-heading-anchor-permalink" href="#Incremental-passivity" title="Permalink"></a></h4><p>There are two cases to consider here. In both cases, the network must have the same number of inputs and outs.</p><ul><li>If <span>$Q = 0, R = -2\nu I, S = I$</span> where <span>$\nu \ge 0$</span>, the model is incrementally passive (incrementally strictly input passive if <span>$\nu &gt; 0$</span>). Mathematically, the following inequality holds.</li></ul><p class="math-container">\[\langle \mathcal{M}_a(u) - \mathcal{M}_b(v), u-v \rangle_T \ge \nu \| u-v\|^2_T\]</p><ul><li>If <span>$Q = -2\rho I, R = 0, S = I$</span> where <span>$\rho &gt; 0$</span>, the model is incrementally strictly output passive. Mathematically, the following inequality holds.</li></ul><p class="math-container">\[\langle \mathcal{M}_a(u) - \mathcal{M}_b(v), u-v \rangle_T \ge \rho \| \mathcal{M}_a(u) - \mathcal{M}_b(v)\|^2_T\]</p><p>For more details on IQCs and their use in RENs, please see <a href="https://ieeexplore.ieee.org/document/10179161">Revay, Wang &amp; Manchester (2021)</a>.</p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../getting_started/">« Getting Started</a><a class="docs-footer-nextpage" href="../developing/">Contributing to the Package »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.25 on <span class="colophon-date" title="Tuesday 28 November 2023 06:43">Tuesday 28 November 2023</span>. Using Julia version 1.9.4.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
